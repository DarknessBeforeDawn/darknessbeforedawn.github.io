

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="mztchaoqun">
  <meta name="keywords" content="hexo,theme,fluid,material,material-design,blog">
  
    <meta name="description" content="大多数AI技术的核心，背后其实都离不开一种计算——矩阵乘法（GEMM）。别把这个当做数学教科书的一种公式计算，实际上 GEMM 就像是深度学习的“心脏”，几乎每个AI模型训练、每次预测，都少不了它的身影。 DeepGEMM 是一个专为 NVIDIA Hopper 架构设计的高效 FP8 矩阵乘法库，支持普通和混合专家模型（MoE）分组矩阵乘法，通过简洁的实现和即时编译技术，实现了高性能和易用性。">
<meta property="og:type" content="article">
<meta property="og:title" content="DeepSeek DeepGEMM">
<meta property="og:url" content="https://mztchaoqun.com.cn/posts/D67_DeepGEMM/index.html">
<meta property="og:site_name" content="Suny的文章">
<meta property="og:description" content="大多数AI技术的核心，背后其实都离不开一种计算——矩阵乘法（GEMM）。别把这个当做数学教科书的一种公式计算，实际上 GEMM 就像是深度学习的“心脏”，几乎每个AI模型训练、每次预测，都少不了它的身影。 DeepGEMM 是一个专为 NVIDIA Hopper 架构设计的高效 FP8 矩阵乘法库，支持普通和混合专家模型（MoE）分组矩阵乘法，通过简洁的实现和即时编译技术，实现了高性能和易用性。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mztchaoqun.com.cn/images/DeepGEMM2.png">
<meta property="article:published_time" content="2025-04-23T13:21:11.000Z">
<meta property="article:modified_time" content="2026-02-27T13:41:45.278Z">
<meta property="article:author" content="mztchaoqun">
<meta property="article:tag" content="DeepSeek">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://mztchaoqun.com.cn/images/DeepGEMM2.png">
  
  
  
  <title>DeepSeek DeepGEMM - Suny的文章</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"mztchaoqun.com.cn","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.1.1"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Suny的文章</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/it-tools/" target="_self">
                <i class="iconfont icon-briefcase"></i>
                <span>it-tools</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                <span>文档</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="https://hexo.fluid-dev.com/docs/start/" target="_self">
                    
                    <span>安装主题</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://hexo.fluid-dev.com/docs/guide/" target="_self">
                    
                    <span>配置指南</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://hexo.fluid-dev.com/docs/icon/" target="_self">
                    
                    <span>图标用法</span>
                  </a>
                
              </div>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/images/post_banner.webp') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="DeepSeek DeepGEMM"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-04-23 21:21" pubdate>
          2025年4月23日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4.2k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          36 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">DeepSeek DeepGEMM</h1>
            
            
              <div class="markdown-body">
                
                <p>大多数AI技术的核心，背后其实都离不开一种计算——矩阵乘法（GEMM）。别把这个当做数学教科书的一种公式计算，实际上
GEMM
就像是深度学习的“心脏”，几乎每个AI模型训练、每次预测，都少不了它的身影。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepGEMM">DeepGEMM</a>
是一个专为 NVIDIA Hopper 架构设计的高效 FP8
矩阵乘法库，支持普通和混合专家模型（MoE）分组矩阵乘法，通过简洁的实现和即时编译技术，实现了高性能和易用性。</p>
<h2 id="一gemm与tensorcore">一、GEMM与TensorCore</h2>
<h3 id="gemm">1.1 GEMM</h3>
<p>GEMM（General Matrix
Multiplications）即通用矩阵乘法，是将两个矩阵的进行相乘的计算。这种方法称为一般矩阵乘法
（GEMM）。科学计算库（如 Numpy、BLAS
等）和大模型都使用了GEMM。此实现仅适用于方阵。这样做是为了避免使算法过于复杂而无法处理矩形矩阵。</p>
<figure>
<img src="/images/GEMM.png" srcset="/img/loading.gif" lazyload alt="标准GEMM">
<figcaption aria-hidden="true">标准GEMM</figcaption>
</figure>
<p>在GPU中，GEMM 定义为运算<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="15.364ex" height="2.059ex" role="img" focusable="false" viewBox="0 -716 6791 910"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mo" transform="translate(1037.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2093.6,0)"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mi" transform="translate(2733.6,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(3483.6,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mo" transform="translate(4464.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(5465,0)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mi" transform="translate(6031,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g></g></g></svg></mjx-container></span>，其中 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.62ex" role="img" focusable="false" viewBox="0 -716 750 716"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g></g></g></svg></mjx-container></span> 和 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.717ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 759 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g></g></g></svg></mjx-container></span> 作为矩阵输入，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.448ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 640 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g></g></g></svg></mjx-container></span>和<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.281ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 566 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g></g></g></svg></mjx-container></span>作为标量输入，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.719ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 760 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g></g></g></svg></mjx-container></span>作为预先存在的矩阵，被输出覆盖。通矩阵乘积
<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="3.414ex" height="1.62ex" role="img" focusable="false" viewBox="0 -716 1509 716"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(750,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g></g></g></svg></mjx-container></span>是<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.448ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 640 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g></g></g></svg></mjx-container></span>等于1且<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.281ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 566 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g></g></g></svg></mjx-container></span>等于0的GEMM。例如，在全连接层的正向传递中，权重矩阵为参数
<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.62ex" role="img" focusable="false" viewBox="0 -716 750 716"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g></g></g></svg></mjx-container></span>，传入激活为参数 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.717ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 759 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g></g></g></svg></mjx-container></span>，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.448ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 640 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g></g></g></svg></mjx-container></span>和<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.281ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 566 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g></g></g></svg></mjx-container></span> 通常分别为 1 和
0。在某些情况下，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.281ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 566 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g></g></g></svg></mjx-container></span>可以是
1。</p>
<p>GPU 通过将输出矩阵划分为图块来实现
GEMM，然后将其分配给线程块。图块大小（Tile
Size）通常是指这些图块的尺寸。每个线程块通过单步执行图块中的 K 维度，从
<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.62ex" role="img" focusable="false" viewBox="0 -716 750 716"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g></g></g></svg></mjx-container></span> 和 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.717ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 759 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g></g></g></svg></mjx-container></span>
矩阵加载所需的值，然后将它们相乘并累加到输出中来计算其输出图块。</p>
<figure>
<img src="/images/GEMM1.png" srcset="/img/loading.gif" lazyload alt="GPU中GEMM的一般计算方法">
<figcaption aria-hidden="true">GPU中GEMM的一般计算方法</figcaption>
</figure>
<h3 id="tensor-core">1.2 Tensor Core</h3>
<p>英伟达GPU 引入了 Tensor Core（张量核心）
来最大限度地提高GEMM的速度。使用 Tensor Core 的要求取决于
英伟达库的版本。</p>
<figure>
<img src="/images/GEMM2.png" srcset="/img/loading.gif" lazyload alt="Tensor Core基本结构">
<figcaption aria-hidden="true">Tensor Core基本结构</figcaption>
</figure>
<p>第一代 Tensor Core 是随 Volta 架构引入的，从 V100
开始，随着数据格式的变化，Tensor Core也在不断更新。</p>
<figure>
<img src="/images/GEMM3.png" srcset="/img/loading.gif" lazyload alt="Tensor Core支持的数据格式">
<figcaption aria-hidden="true">Tensor Core支持的数据格式</figcaption>
</figure>
<p>GEMM的实现效率与Tensor
Core结构和数据格式密切相关，受数据的调度方式影响很大。因此基于Tensor
Core的硬件架构进行计算优化就显得十分重要。好的优化往往能取得数倍的性能提升。</p>
<h2 id="二deepgemm">二、DeepGEMM</h2>
<ul>
<li><strong>FP8 低精度支持</strong>：DeepGEMM
最大的特色在于从架构上优先设计为 FP8
服务。传统GEMM库主要优化FP16和FP32，而DeepGEMM针对FP8的特殊性进行了优化设计。</li>
<li><strong>极致性能与极简核心实现</strong>：DeepGEMM在NVIDIA Hopper
GPU上实现了高达1350+ FP8
TFLOPS的计算性能，同时其核心代码仅有约300行</li>
<li><strong>JIT 即时编译</strong>：DeepGEMM
不是预先编译好所有可能配置的内核，而是利用 JIT
在运行时生成最佳内核。例如，根据矩阵大小、FP8尺度等参数，JIT
会即时优化指令顺序和寄存器分配。</li>
</ul>
<h3 id="fp8-支持优化">2.1 FP8 支持优化</h3>
<p>使用FP8框架进行训练的主要挑战在于精度与误差的处理，DeepSeek为其FP8低比特训练框架做了以下优化：</p>
<ol type="1">
<li><strong>细粒度量化</strong></li>
</ol>
<p>将数据分解成更小的组，每个组都使用特定乘数进行调整以保持高精度。这一方法类似于Tile-Wise或Block-Wise。对于激活，在1x128大小的基础上对计算数据进行分组和缩放;对于权重，以128x128大小对计算数据进行分组和缩放。该方法可以根据最大或最小数据调整缩放系数，来更好的适应计算中的异常值。</p>
<ol start="2" type="1">
<li><strong>在线量化</strong>
为了提高精度并简化框架，该框架在线计算每个1x128激活块或128x128权重块的最大绝对值，在线推算缩放因子，然后将激活或权重在线转化为FP8格式，而不是采用静态的历史数据。相对静态的量化方法，该方法可以获得更高的转换精度，减小误差的累积。</li>
</ol>
<p><img src="/images/DeepGEMM2.png" srcset="/img/loading.gif" lazyload></p>
<ol start="3" type="1">
<li><strong>提高累加精度</strong></li>
</ol>
<p>FP8在大量累加时会累积出现随机误差。例如FP8 GEMM在英伟达H800
GPU上的累加精度保留14位左右，明显低于FP32累加精度。以K=
4096的两个随机矩阵的GEMM运算为例，Tensor
Core中的有限累加精度可导致最大相对误差接近2%。DeepSeek将中间结果储存计算升级为FP32（32位浮点），实行高精度累加，然后再转换回FP8，以降低大量微小误差累加带来的训练偏差。</p>
<ol start="4" type="1">
<li><strong>低精度/混合精度存储与通信</strong></li>
</ol>
<p>为了进一步减少MoE训练中的显存和通信开销，该框架基于FP8进行数据/参数缓存和处理激活，以节省显存与缓存空间并提升性能，并在BF16（16位浮点数）中存储低精度优化器状态。该框架中以下组件保持原始精度（例如BF16或FP32）：嵌入模块、MoE门控模块、归一化算子和注意力算子，以确保模型的动态稳定训练。为保证数值稳定性，以高精度存储主要权重、权重梯度和优化器状态。</p>
<h3 id="持久化warp专业化">2.2 持久化Warp专业化</h3>
<p>Warp 的概念是 NVIDIA GPU
架构中的一个重要特性，它使得开发者能够更细致地控制线程的执行，以优化并行计算的性能。
在 CUDA 编程模型中，<strong>Warp 是 GPU
上并行执行的最小单元</strong>。一个 Warp 包含 32
个线程，这些线程在同一个周期内执行相同的指令。这意味着，如果一个 Warp
中的所有线程都执行相同的操作，那么它们可以并行地在 GPU
上执行，从而提高计算效率。</p>
<p>遵循CUTLASS的设计，DeepGEMM中的内核是warp专业化的，能够重叠数据移动、张量核心MMA指令和CUDA核心提升。下图展示了这一过程的简化示意图：</p>
<figure>
<img src="/images/design.png" srcset="/img/loading.gif" lazyload alt="DeepGEMM的Warp优化">
<figcaption aria-hidden="true">DeepGEMM的Warp优化</figcaption>
</figure>
<ul>
<li><strong>TMA Warps</strong>：负责异步数据加载，通过 TMA
指令减少内存访问延迟。</li>
<li><strong>Math Warps</strong>：执行实际的矩阵乘法计算（WGMMA
表示张量核心矩阵乘法）。</li>
<li><strong>Promotion</strong>：在计算过程中进行数据的累加操作。</li>
</ul>
<h3 id="tensor-memory-accelerator-tma">2.3 Tensor Memory Accelerator
(TMA)</h3>
<p>Tensor Memory Accelerator（TMA） 是NVIDIA
Hopper架构中的一项新功能，它旨在加速GPU的内存访问。TMA通过使用全局内存（GMEM）和共享内存（SMEM）进行数据复制，从而提高GPU的整体性能。
在DeepGEMM中，TMA被用于以下操作：</p>
<ul>
<li><strong>TMA
多播（Multicast）</strong>：一次性将数据广播到多个计算单元，减少重复加载。</li>
<li><strong>TMA
描述符预取</strong>：提前加载数据地址信息，避免计算过程中的延迟。</li>
<li>用于LHS、LHS缩放因子和RHS矩阵的TMA加载</li>
<li>用于输出矩阵的TMA存储</li>
<li><strong>效果</strong>：在 DeepSeek-V3 的 MoE 模型中，TMA
使数据搬运效率提升 30%，显著减少计算等待时间。</li>
</ul>
<h3 id="动态-jit-编译">2.4 动态 JIT 编译</h3>
<h4 id="jit-技术的定义与原理">2.4.1 JIT 技术的定义与原理</h4>
<p><strong>即时编译（JIT）是一种在程序运行时动态生成和优化代码的技术</strong>。与传统的编译方式（如提前编译，Ahead-Of-Time，AOT）不同，JIT
编译器不会在程序安装或部署时生成最终的可执行代码，而是在程序运行时根据实际的输入和运行环境动态生成优化后的代码。这种技术的<strong>核心思想是“延迟编译”</strong>，即<strong>在代码真正需要执行时才进行编译和优化</strong>，从而针对具体的运行场景生成最高效的目标代码。</p>
<p><img src="/images/DeepGEMM3.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="jit-技术的优势">2.4.2 JIT 技术的优势</h4>
<p>JIT
技术在现代计算中具有广泛的应用，尤其是在高性能计算和动态语言运行环境中。它相比传统的静态编译方式具有以下显著优势：</p>
<ul>
<li><strong>更高的性能</strong>：JIT
编译器可以根据运行时的具体输入和硬件环境动态生成优化代码。例如，它可以针对不同的矩阵大小、数据类型或硬件特性选择最适合的算法和优化策略，从而实现比静态编译更高的性能。</li>
<li><strong>灵活性与可扩展性</strong>：由于 JIT
编译器在运行时生成代码，因此它可以<strong>轻松适应不同的硬件架构和输入数据特征</strong>。这种灵活性使得
JIT 技术特别适合于需要处理多种输入场景和硬件环境的应用程序。</li>
<li><strong>减少编译时间与资源消耗</strong>：在传统的静态编译中，编译器需要考虑所有可能的输入情况并生成通用的代码。这往往导致复杂的编译过程和较长的编译时间。而
JIT
编译器只需在运行时<strong>针对当前输入生成代码</strong>，因此可以显著减少编译时间和资源消耗。</li>
</ul>
<h4 id="在-deepgemm-中的应用">2.4.3 在 DeepGEMM 中的应用</h4>
<p>DeepGEMM
采用完全即时编译（JIT）设计，安装时无需编译。所有内核在运行时使用轻量级
JIT 实现进行编译。这种方法具有以下几个优点：</p>
<ul>
<li><strong>GEMM形状、块大小和流水线阶段数被视为编译时常量</strong>
<ul>
<li>节省寄存器</li>
<li>编译器可以进行更多优化</li>
</ul></li>
<li><strong>自动选择块大小、warpgroup数量、最佳流水线阶段和TMA集群大小</strong>
<ul>
<li>但没有自动调优，确定性地选择最佳方案</li>
</ul></li>
<li><strong>完全展开MMA流水线，为编译器提供更多优化机会</strong>
<ul>
<li>对于小形状非常重要</li>
</ul></li>
</ul>
<h3 id="其他">2.5 其他</h3>
<ol type="1">
<li><strong>FFMA 指令交错优化</strong></li>
</ol>
<p>DeepGEMM 通过修改编译后的 GPU
指令（SASS），在<strong>FFMA（浮点乘加）指令</strong>中插入<strong>Yield</strong>和<strong>Reuse</strong>控制位，实现了10%
以上的性能提升。</p>
<p>原来的GPU线程会因为资源竞争导致停滞，现在是相当于指令重排，让某些线程主动让出计算资源，从而减少浪费。</p>
<ol start="2" type="1">
<li><strong>支持分组GEMM</strong></li>
</ol>
<p>与 CUTLASS 中传统的分组 GEMM 不同，DeepGEMM 仅对 M 轴进行分组，而 N
和 K 可保持不变。（可专门针对 MoE 模型中的专家量身定制）</p>
<ol start="3" type="1">
<li><strong>使用PTX指令进行性能优化</strong></li>
</ol>
<p>使用stmatrix PTX 指令。</p>
<h2 id="三代码分析">三、代码分析</h2>
<h3 id="fp8-提升速度的基础">3.1 FP8： 提升速度的基础</h3>
<p>为什么是 FP8？这都是为了效率。torch.float8_e4m3fn与 BF16 的 16 位或
FP32 的 32 位相比，FP8（特别是在 PyTorch 中）仅使用 8
位来表示浮点数。这意味着：</p>
<ul>
<li><strong>减少内存占用</strong>：
将存储权重和激活所需的内存减少一半。</li>
<li><strong>增加内存带宽</strong>：每个时钟周期移动两倍的数据。</li>
<li><strong>更快的张量核心操作</strong>： Hopper 的张量核心专为 FP8
设计，可实现峰值性能。</li>
</ul>
<p>然而，FP8 的动态范围较小，这就是 DeepGEMM
包含细粒度缩放的原因。这涉及动态调整比例因子，以确保相乘的值落在 FP8
的可表示范围内。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">per_token_cast_to_fp8</span>(<span class="hljs-params">x: torch.Tensor</span>) -&gt; <span class="hljs-type">Tuple</span>[torch.Tensor, torch.Tensor]:<br>    <span class="hljs-keyword">assert</span> x.dim() == <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> x.size(<span class="hljs-number">1</span>) % <span class="hljs-number">128</span> == <span class="hljs-number">0</span><br>    m, n = x.shape<br>    x_view = x.view(m, -<span class="hljs-number">1</span>, <span class="hljs-number">128</span>) <span class="hljs-comment"># View tensor into blocks of 128</span><br>    x_amax = x_view.<span class="hljs-built_in">abs</span>().<span class="hljs-built_in">float</span>().amax(dim=<span class="hljs-number">2</span>).view(m, -<span class="hljs-number">1</span>).clamp(<span class="hljs-number">1e-4</span>) <span class="hljs-comment"># Calculate max abs value</span><br>    <span class="hljs-keyword">return</span> (x_view * (<span class="hljs-number">448.0</span> / x_amax.unsqueeze(<span class="hljs-number">2</span>))).to(torch.float8_e4m3fn).view(m, n), (x_amax / <span class="hljs-number">448.0</span>).view(m, -<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p>此代码片段演示了 DeepGEMM 如何缩放输入张量x以适应 FP8
范围。它计算每个 128 个元素块的最大绝对值
(x_amax)，并使用此值缩放输入，然后将其转换为
FP8。然后存储缩放因子以供以后使用。</p>
<h3 id="tma数据迁移大师">3.2 TMA：数据迁移大师</h3>
<p>张量内存加速器 (TMA) 是 Hopper
上的一项重大变革。它是专用于异步数据移动的硬件单元，可释放 CUDA
核心进行计算。DeepGEMM 利用 TMA 实现以下功能：</p>
<ul>
<li><strong>加载 LHS、RHS 和缩放因子</strong>：
更快、更有效地获取数据。</li>
<li><strong>存储输出矩阵</strong>： 异步写入全局内存。</li>
<li><strong>TMA 多播</strong>： 跨多个线程复制 LHS
数据，减少内存流量。</li>
</ul>
<p>TMA 核心的 ASCII 图（简化）：</p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">+-----------------------------------------------------+<br>|<span class="hljs-string">                 Tensor Memory Accelerator (TMA)       </span>|<br>+-----------------------------------------------------+<br>|<span class="hljs-string">  +--------------+   +--------------+   +--------------+ </span>|<br>|<span class="hljs-string">  </span>|<span class="hljs-string">  Load Unit   </span>|<span class="hljs-string">--&gt;</span>|<span class="hljs-string">  TMA Cache   </span>|<span class="hljs-string">--&gt;</span>|<span class="hljs-string">  CUDA Cores  </span>|<span class="hljs-string"> </span>|<br>|<span class="hljs-string">  +--------------+   +--------------+   +--------------+ </span>|<br>|<span class="hljs-string">       ^   </span>|<span class="hljs-string">            ^   </span>|<span class="hljs-string">            ^   </span>|<span class="hljs-string">           </span>|<br>|<span class="hljs-string">       </span>|<span class="hljs-string">   </span>|<span class="hljs-string">            </span>|<span class="hljs-string">   </span>|<span class="hljs-string">            </span>|<span class="hljs-string">   </span>|<span class="hljs-string">           </span>|<br>|<span class="hljs-string">  +--------------+   +--------------+   +--------------+ </span>|<br>|<span class="hljs-string">  </span>|<span class="hljs-string"> Store Unit   </span>|<span class="hljs-string">&lt;--</span>|<span class="hljs-string">  TMA Cache   </span>|<span class="hljs-string">&lt;--</span>|<span class="hljs-string">  CUDA Cores  </span>|<span class="hljs-string"> </span>|<br>|<span class="hljs-string">  +--------------+   +--------------+   +--------------+ </span>|<br>|<span class="hljs-string">       </span>|<span class="hljs-string">            </span>|<span class="hljs-string">            </span>|<span class="hljs-string">                       </span>|<br>|<span class="hljs-string">  +--------------+   +--------------+   +--------------+ </span>|<br>|<span class="hljs-string">  </span>|<span class="hljs-string">  Global Mem  </span>|<span class="hljs-string">   </span>|<span class="hljs-string">  Multicast   </span>|<span class="hljs-string">   </span>|<span class="hljs-string">               </span>|<br>|<span class="hljs-string">  +--------------+   +--------------+   +--------------+ </span>|<br>+-----------------------------------------------------+<br></code></pre></td></tr></table></figure>
<p>TMA 充当全局内存和 CUDA
核心之间的中介，允许数据传输与计算并行进行。多播功能通过减少加载 LHS
矩阵所需的内存访问次数进一步提高了性能。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">auto</span> tma_a_desc = GemmType::<span class="hljs-built_in">make_2d_tma_a_desc</span>(lhs, m);<br><span class="hljs-keyword">auto</span> tma_b_desc = GemmType::<span class="hljs-built_in">make_2d_tma_b_desc</span>(rhs);<br><span class="hljs-keyword">auto</span> tma_scales_a_desc = GemmType::<span class="hljs-built_in">make_2d_tma_scales_a_desc</span>(lhs_scales, m);<br><span class="hljs-keyword">auto</span> tma_d_desc = GemmType::<span class="hljs-built_in">make_2d_tma_d_desc</span>(out, m);<br>GemmType::<span class="hljs-built_in">run</span>(out, rhs_scales, <span class="hljs-literal">nullptr</span>,<br>              m,<br>              tma_a_desc, tma_b_desc, tma_scales_a_desc, tma_d_desc,<br>              stream, num_sms, smem_size);<br></code></pre></td></tr></table></figure>
<p>此 C++ 代码片段展示了 DeepGEMM 如何为
LHS、RHS、缩放因子和输出矩阵配置 TMA 描述符。这些描述符告诉 TMA
如何加载、存储和多播数据。</p>
<p>DeepGEMM遵循 CUTLASS 设计， 其内核为 warp
专用，支持重叠式的数据移动、张量核心 MMA 指令和 CUDA 核心优化。</p>
<ul>
<li><strong>TMA（Tensor Memory Accelerator）</strong>：Hopper
架构的硬件特性，用于异步数据加载或移动（如 LHS
矩阵、缩放因子等），减少内存访问延迟。</li>
<li><strong>指令重叠</strong>：内核采用 warp-specialized
设计，允许数据移动、张量核心 MMA（矩阵乘加）指令和 CUDA
核心累加操作重叠。</li>
<li><strong>FP8 微调</strong>：通过修改编译后二进制的
FFMA（融合乘加）指令，调整 yield 和 reuse
位，进一步提升性能（据称在某些情况下提升 10%+）。</li>
<li><strong>区块调度器</strong>：通过统一的调度器调度所有非分组和分组内核，栅格化（Rasterization
）以增强 L2 缓存的复用/重用。</li>
</ul>
<p>这些优化使得 DeepGEMM
在大多数矩阵大小上优于专家调优的内核，同时保持代码简洁。</p>
<figure>
<img src="/images/design.png" srcset="/img/loading.gif" lazyload alt="DeepGEMM的Warp优化">
<figcaption aria-hidden="true">DeepGEMM的Warp优化</figcaption>
</figure>
<h3 id="jit可变形的内核">3.3 JIT：可变形的内核</h3>
<p>DeepGEMM 采用即时 (JIT)
编译。这意味着内核在运行时进行编译，并根据特定的矩阵形状和硬件配置进行定制。这允许：</p>
<ul>
<li><strong>形状特定优化</strong>： 为每个 GEMM
操作选择最佳的块大小、warpgroup 数量和管道阶段。</li>
<li><strong>编译器展开</strong>： 完全展开 MMA
管道，为编译器提供更多的优化机会，尤其是对于小形状。</li>
<li><strong>寄存器计数控制</strong>：针对不同的 warpgroups
微调寄存器的使用。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">runtime = jit_tuner.compile_and_tune(<br>    name=<span class="hljs-string">'gemm_fp8_fp8_bf16_nt'</span>,<br>    keys={<span class="hljs-string">'N'</span>: n, <span class="hljs-string">'K'</span>: k, <span class="hljs-string">'BLOCK_M'</span>: block_m, <span class="hljs-string">'BLOCK_N'</span>: block_n,<br>          <span class="hljs-string">'NUM_STAGES'</span>: num_stages, <span class="hljs-string">'NUM_TMA_MULTICAST'</span>: num_tma_multicast},<br>    space=(),<br>    includes=includes,<br>    arg_defs=((<span class="hljs-string">'lhs'</span>, torch.float8_e4m3fn), (<span class="hljs-string">'lhs_scales'</span>, torch.<span class="hljs-built_in">float</span>),<br>              (<span class="hljs-string">'rhs'</span>, torch.float8_e4m3fn), (<span class="hljs-string">'rhs_scales'</span>, torch.<span class="hljs-built_in">float</span>),<br>              (<span class="hljs-string">'out'</span>, torch.bfloat16), (<span class="hljs-string">'m'</span>, <span class="hljs-built_in">int</span>),<br>              (<span class="hljs-string">'stream'</span>, torch.cuda.Stream), (<span class="hljs-string">'num_sms'</span>, <span class="hljs-built_in">int</span>), (<span class="hljs-string">'smem_size'</span>, <span class="hljs-built_in">int</span>)),<br>    template=template,<br>    args=args<br>)<br></code></pre></td></tr></table></figure>
<p>此 Python 代码片段展示了 DeepGEMM 如何使用 JIT
编译器为给定的矩阵形状和硬件配置生成专用内核。keys字典指定用于自定义内核的参数。</p>
<h3 id="ffma-交错sass-级别的秘密武器">3.4 FFMA 交错：SASS
级别的秘密武器</h3>
<p>这就是事情变得真正有趣的地方。DeepGEMM 在 SASS（CUDA
汇编）级别进行了低级优化。通过分析编译后的代码，开发人员发现翻转FFMA（融合乘加）指令中的特定位可以提高性能。</p>
<ul>
<li><strong>扭曲级并行性</strong>：
翻转的位控制yield行为，可能允许扭曲交错执行并改善扭曲级并行性。</li>
<li><strong>寄存器重用</strong>： 位reuse也被翻转，创造了更多将 MMA
指令与提升FFMA指令重叠的机会。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">modify_segment</span>(<span class="hljs-params">m, name, ffma_lines</span>):<br>    <span class="hljs-comment"># ... (code to extract and modify FFMA instructions) ...</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_lines // <span class="hljs-number">2</span>):<br>        <span class="hljs-comment"># ...</span><br>        reused = (high_hex &amp; <span class="hljs-number">0x0800000000000000</span>) != <span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> reused:<br>            is_first_occurred = dst_reg <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> dst_reg_set<br>            <span class="hljs-keyword">if</span> is_first_occurred <span class="hljs-keyword">or</span> (last_reused <span class="hljs-keyword">and</span> dst_reg == last_dst_reg):<br>                <span class="hljs-comment"># Modify the `reuse` and `yield` bits</span><br>                <span class="hljs-keyword">assert</span> high_hex &amp; <span class="hljs-number">0x0800200000000000</span>, <span class="hljs-string">f"<span class="hljs-subst">{<span class="hljs-built_in">hex</span>(high_hex)}</span>"</span><br>                high_hex ^= <span class="hljs-number">0x0800200000000000</span><br>                reused = <span class="hljs-literal">False</span><br>                num_changed += <span class="hljs-number">1</span><br>        <span class="hljs-comment"># ...</span><br></code></pre></td></tr></table></figure>
<p>此 Python 代码片段展示了 DeepGEMM 如何修改FFMA已编译的 SASS
代码中的指令。它提取指令的十六进制表示形式，翻转reuse和yield位，然后用修改后的指令替换原始指令。</p>
<h3 id="moe-特定分组连续和掩蔽">3.5 MoE 特定分组：连续和掩蔽</h3>
<p>MoE 模型引入了新的复杂度。DeepGEMM 使用两种常见 MoE
布局的专用内核来解决这个问题：</p>
<ul>
<li><strong>连续布局</strong>：
专家处理不同数量的标记，这些标记被连接成一个张量。</li>
<li><strong>掩蔽布局</strong>：
在推理解码期间使用，其中每个专家收到的标记数量是未知的。</li>
</ul>
<p>连续布局:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">deep_gemm.m_grouped_gemm_fp8_fp8_bf16_nt_contiguous(x_fp8, y_fp8, out, m_indices)<br></code></pre></td></tr></table></figure>
<p>在连续布局中，m_indices张量指定 LHS
矩阵的每一行属于哪个专家。这使得内核能够有效地为每个专家执行 GEMM
操作。</p>
<p>掩蔽布局:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">deep_gemm.m_grouped_gemm_fp8_fp8_bf16_nt_masked(x_fp8, y_fp8, out, masked_m, expected_m)<br></code></pre></td></tr></table></figure>
<p>在掩码布局中，masked_m张量指定每组中有效行的数量。这允许内核跳过无效行的计算，从而提高性能。</p>
<h3 id="与其他库相比">3.6 与其他库相比</h3>
<ul>
<li><strong>vLLM</strong>： vLLM
通过优化内存管理、调度和量化，专注于高吞吐量推理。虽然 vLLM
可能在内部使用优化的 GEMM 内核，但 DeepGEMM 为 Hopper 上的 FP8 GEMM
提供了更专业的解决方案。</li>
<li><strong>CUTLASS</strong>： CUTLASS 是一个全面的线性代数 CUDA
内核库。DeepGEMM 利用了 CUTLASS
的一些概念，但避免了对其模板和代数的过度依赖，而是选择了更简单、更易于访问的设计。</li>
<li><strong>CuTe</strong>：专注于张量操作的抽象，灵活但需要较深理解。</li>
</ul>
<p>DeepGEMM 的主要优势在于它专注于最大限度地提高 Hopper 上 FP8 GEMM
的性能，尤其是在 MoE 模型的背景下。它通过结合 TMA 掌握、JIT 编译和 FFMA
交错等低级优化来实现这一点。</p>
<h2 id="reference">Reference</h2>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/2648247671">DeepSeek - Day3:
一篇搞懂DeepGEMM</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26437292382">DeepSeek
开源Day（3）DeepGEMM深入分析</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepGEMM">Github
DeepGEMM</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/Eternity__Aurora/article/details/146311774?spm=1001.2014.3001.5502">【DeepSeek开源周】Day
3：DeepGEMM 学习笔记</a></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/LLM/" class="category-chain-item">LLM</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/LLM/" class="print-no-link">#LLM</a>
      
        <a href="/tags/DeepSeek/" class="print-no-link">#DeepSeek</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>DeepSeek DeepGEMM</div>
      <div>https://mztchaoqun.com.cn/posts/D67_DeepGEMM/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>mztchaoqun</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年4月23日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/posts/D68_DualPipe_EPLB/" title="DeepSeek DualPipe &amp; EPLB">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">DeepSeek DualPipe &amp; EPLB</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/posts/D66_DeepEP/" title="DeepSeek DeepEP">
                        <span class="hidden-mobile">DeepSeek DeepEP</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <!-- <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> --> <div class="flex flex-auto justify-center [&amp;>*]:px-[16px] [&amp;>a]:no-underline  mb-[8px]"><a target="_blank" class="flex items-center text-[#A1A1A1] hover:text-white " href="https://www.beian.gov.cn/portal/registerSystemInfo?recordcode=51015602000856"><img alt="川公网安备" fetchpriority="high" width="20" height="20" decoding="async" data-nimg="1" class="mr-[6px]" src="/images/ga.png" srcset="/img/loading.gif" lazyload style="color: transparent;">&nbsp;川公网安备&nbsp;51015602000856号</a>&emsp;<a target="_blank" class="text-[#A1A1A1] hover:text-white " href="https://beian.miit.gov.cn/">蜀ICP备2024061486号-1</a></div> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
