

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="mztchaoqun">
  <meta name="keywords" content="hexo,theme,fluid,material,material-design,blog">
  
    <meta name="description" content="Reflection Agents Reflection是一种提升Agent和类似AI系统质量和成功率的prompt策略，它涉及prompt大型语言模型（LLM）回顾和评判其过去的行为，有时还会结合额外的外部信息，如工具观察结果。 System 2相比与System 1更系统化和并且具有反思性。当正确应用时，Reflection可以帮助大型语言模型（LLM）系统打破System 1的思维模式，更接">
<meta property="og:type" content="article">
<meta property="og:title" content="LangGraph(六)——Reflection Agents">
<meta property="og:url" content="https://mztchaoqun.com.cn/posts/D37_Refection_Agents/index.html">
<meta property="og:site_name" content="Suny的文章">
<meta property="og:description" content="Reflection Agents Reflection是一种提升Agent和类似AI系统质量和成功率的prompt策略，它涉及prompt大型语言模型（LLM）回顾和评判其过去的行为，有时还会结合额外的外部信息，如工具观察结果。 System 2相比与System 1更系统化和并且具有反思性。当正确应用时，Reflection可以帮助大型语言模型（LLM）系统打破System 1的思维模式，更接">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mztchaoqun.com.cn/images/Reflection_Agents.jpeg">
<meta property="article:published_time" content="2024-09-13T08:35:41.000Z">
<meta property="article:modified_time" content="2026-02-27T13:41:45.272Z">
<meta property="article:author" content="mztchaoqun">
<meta property="article:tag" content="Agent">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="LLM学习笔记">
<meta property="article:tag" content="LangGraph">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://mztchaoqun.com.cn/images/Reflection_Agents.jpeg">
  
  
  
  <title>LangGraph(六)——Reflection Agents - Suny的文章</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"mztchaoqun.com.cn","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.1.1"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Suny的文章</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/it-tools/" target="_self">
                <i class="iconfont icon-briefcase"></i>
                <span>it-tools</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                <span>文档</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="https://hexo.fluid-dev.com/docs/start/" target="_self">
                    
                    <span>安装主题</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://hexo.fluid-dev.com/docs/guide/" target="_self">
                    
                    <span>配置指南</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://hexo.fluid-dev.com/docs/icon/" target="_self">
                    
                    <span>图标用法</span>
                  </a>
                
              </div>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/images/post_banner.webp') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="LangGraph(六)——Reflection Agents"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-09-13 16:35" pubdate>
          2024年9月13日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          3.6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          30 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">LangGraph(六)——Reflection Agents</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="reflection-agents">Reflection Agents</h2>
<p>Reflection是一种提升Agent和类似AI系统质量和成功率的prompt策略，它涉及prompt大型语言模型（LLM）回顾和评判其过去的行为，有时还会结合额外的外部信息，如工具观察结果。</p>
<p>System 2相比与System
1更系统化和并且具有反思性。当正确应用时，Reflection可以帮助大型语言模型（LLM）系统打破System
1的思维模式，更接近表现出System 2类型的行为。</p>
<p><img src="/images/System-12-White-1.png" srcset="/img/loading.gif" lazyload></p>
<p>Reflection需要花一些时间，但是使用一些额外的计算资源可以获得更好的输出，但对于知识密集型任务来说，这是值得的，在这些任务中质量比速度更重要。</p>
<h3 id="basic-reflection">1. Basic Reflection</h3>
<ul>
<li><strong>组成</strong>：由两个LLM调用组成，一个是生成器（generator），尝试直接响应用户请求；另一个是反思器（reflector），扮演教师角色，对初始响应提供建设性评判。</li>
<li><strong>循环</strong>：固定次数的循环，最终生成的输出被返回。</li>
</ul>
<figure>
<img src="/images/reflection.png" srcset="/img/loading.gif" lazyload alt="Simple Reflection Loop">
<figcaption aria-hidden="true">Simple Reflection Loop</figcaption>
</figure>

    <div class="fold">
      <div class="fold-title fold-info collapsed" data-toggle="collapse" href="#collapse-991ee5de" role="button" aria-expanded="false" aria-controls="collapse-991ee5de">
        <div class="fold-arrow">▶</div>LangGraph代码示例
      </div>
      <div class="fold-collapse collapse" id="collapse-991ee5de">
        <div class="fold-content">
          <p><strong>Generate</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain_fireworks <span class="hljs-keyword">import</span> ChatFireworks<br><span class="hljs-keyword">from</span> langchain_core.messages <span class="hljs-keyword">import</span> AIMessage, BaseMessage, HumanMessage<br><span class="hljs-keyword">from</span> langchain_core.prompts <span class="hljs-keyword">import</span> ChatPromptTemplate, MessagesPlaceholder<br><br>prompt = ChatPromptTemplate.from_messages(<br>    [<br>        (<br>            <span class="hljs-string">"system"</span>,<br>            <span class="hljs-string">"You are an essay assistant tasked with writing excellent 5-paragraph essays."</span><br>            <span class="hljs-string">" Generate the best essay possible for the user's request."</span><br>            <span class="hljs-string">" If the user provides critique, respond with a revised version of your previous attempts."</span>,<br>        ),<br>        MessagesPlaceholder(variable_name=<span class="hljs-string">"messages"</span>),<br>    ]<br>)<br>llm = ChatFireworks(<br>    model=<span class="hljs-string">"accounts/fireworks/models/mixtral-8x7b-instruct"</span>,<br>    max_tokens=<span class="hljs-number">32768</span>,<br>)<br>generate = prompt | llm<br></code></pre></td></tr></table></figure><p><strong>Reflect</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">reflection_prompt = ChatPromptTemplate.from_messages(<br>    [<br>        (<br>            <span class="hljs-string">"system"</span>,<br>            <span class="hljs-string">"You are a teacher grading an essay submission. Generate critique and recommendations for the user's submission."</span><br>            <span class="hljs-string">" Provide detailed recommendations, including requests for length, depth, style, etc."</span>,<br>        ),<br>        MessagesPlaceholder(variable_name=<span class="hljs-string">"messages"</span>),<br>    ]<br>)<br>reflect = reflection_prompt | llm<br></code></pre></td></tr></table></figure><p><strong>Graph</strong> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Sequence</span><br><br><span class="hljs-keyword">from</span> langgraph.graph <span class="hljs-keyword">import</span> END, MessageGraph<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">generation_node</span>(<span class="hljs-params">state: <span class="hljs-type">Sequence</span>[BaseMessage]</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">await</span> generate.ainvoke({<span class="hljs-string">"messages"</span>: state})<br><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">reflection_node</span>(<span class="hljs-params">messages: <span class="hljs-type">Sequence</span>[BaseMessage]</span>) -&gt; <span class="hljs-type">List</span>[BaseMessage]:<br>    <span class="hljs-comment"># Other messages we need to adjust</span><br>    cls_map = {<span class="hljs-string">"ai"</span>: HumanMessage, <span class="hljs-string">"human"</span>: AIMessage}<br>    <span class="hljs-comment"># First message is the original user request. We hold it the same for all nodes</span><br>    translated = [messages[<span class="hljs-number">0</span>]] + [<br>        cls_map[msg.<span class="hljs-built_in">type</span>](content=msg.content) <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> messages[<span class="hljs-number">1</span>:]<br>    ]<br>    res = <span class="hljs-keyword">await</span> reflect.ainvoke({<span class="hljs-string">"messages"</span>: translated})<br>    <span class="hljs-comment"># We treat the output of this as human feedback for the generator</span><br>    <span class="hljs-keyword">return</span> HumanMessage(content=res.content)<br><br><br>builder = MessageGraph()<br>builder.add_node(<span class="hljs-string">"generate"</span>, generation_node)<br>builder.add_node(<span class="hljs-string">"reflect"</span>, reflection_node)<br>builder.set_entry_point(<span class="hljs-string">"generate"</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">should_continue</span>(<span class="hljs-params">state: <span class="hljs-type">List</span>[BaseMessage]</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(state) &gt; <span class="hljs-number">6</span>:<br>        <span class="hljs-comment"># End after 3 iterations</span><br>        <span class="hljs-keyword">return</span> END<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">"reflect"</span><br><br><br>builder.add_conditional_edges(<span class="hljs-string">"generate"</span>, should_continue)<br>builder.add_edge(<span class="hljs-string">"reflect"</span>, <span class="hljs-string">"generate"</span>)<br>graph = builder.<span class="hljs-built_in">compile</span>()<br></code></pre></td></tr></table></figure></p><p><code>MessageGraph</code>代表一个有状态的图，其中的“状态”仅仅是一系列消息的列表。每次调用<code>Generator</code>或<code>Reflector</code>节点时，它都会在状态的末尾追加一条消息。最终结果由<code>Generator</code>节点返回。</p><p><strong>执行</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">async</span> <span class="hljs-keyword">for</span> event <span class="hljs-keyword">in</span> graph.astream(<br>    [<br>        HumanMessage(<br>            content=<span class="hljs-string">"Generate an essay on the topicality of The Little Prince and its message in modern life"</span><br>        )<br>    ],<br>):<br>    <span class="hljs-built_in">print</span>(event)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"---"</span>)<br></code></pre></td></tr></table></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs text"><br>{'generate': AIMessage(content='Title: The Little Prince: A Timeless Message for Modern Life\n\nIntroduction:\nAntoine de Saint-Exupéry\'s "The Little Prince" is a classic novella that has captured the hearts of millions since its publication in 1943. While it has been over seven decades since its release, the story remains incredibly topical and relevant to modern life. This essay explores the themes of the novel and how they continue to resonate with people in the contemporary world.\n\nBody Paragraph 1: The Relevance of Relationships\nThe Little Prince teaches us about the importance of meaningful relationships in our lives. In the story, the prince leaves his tiny asteroid to explore the universe and meets various inhabitants of other planets, each representing a different aspect of adult existence. These encounters highlight the superficiality of many adult relationships, emphasizing the value of genuine connections. In modern life, where people are often more isolated than ever, despite technological advancements, this message serves as a reminder to prioritize and nurture our real-life relationships.\n\nBody Paragraph 2: The Dangers of Obsession and Materialism\nAnother timely message from The Little Prince is the danger of becoming obsessed with material possessions and success. The novel satirizes the absurdity of the grown-up world, where people are preoccupied with superficial matters, such as the number of baobab trees on a planet. This theme resonates with modern society, where materialism and consumerism have reached unprecedented levels. The Little Prince\'s message encourages us to reassess our priorities and focus on what truly matters in life.\n\nBody Paragraph 3: The Significance of Vulnerability and Emotional Honesty\nThe Little Prince also emphasizes the importance of vulnerability and emotional honesty. Throughout the story, the prince displays a level of emotional intelligence that is both refreshing and thought-provoking. He is not afraid to express his feelings, admit his mistakes, or show his love for others. This message is particularly relevant in today\'s world, where emotional intelligence and mental health are increasingly recognized as essential components of a fulfilling life.\n\nConclusion:\nIn conclusion, The Little Prince remains a topical and powerful work that delivers a timeless message for modern life. Its exploration of relationships, the dangers of obsession and materialism, and the significance of vulnerability and emotional honesty are as relevant today as they were when the book was first published. By embracing the wisdom of The Little Prince, we can better navigate our complex, fast-paced world and lead more meaningful, fulfilling lives.\n\nRevised Essay (if necessary):\n\nTitle: The Little Prince: A Timeless Message for Modern Life\n\nIntroduction:\nAntoine de Saint-Exupéry\'s "The Little Prince" is a timeless novella that has captured the hearts of millions since its publication in 1943. Despite the passage of over seven decades, the story remains incredibly relevant and topical in modern life. This essay explores the novel\'s themes and how they continue to resonate with people in the contemporary world.\n\nBody Paragraph 1: The Importance of Authentic Relationships\nThe Little Prince teaches us about the significance of authentic relationships in our lives. The story highlights the superficiality of many adult relationships, emphasizing the value of genuine connections. This theme is particularly relevant in today\'s world, where people are often more isolated than ever, despite technological advancements. The Little Prince\'s message encourages us to prioritize and nurture our real-life relationships, fostering a sense of community and belonging.\n\nBody Paragraph 2: The Dangers of Materialism and Superficiality\nAnother timely message from The Little Prince is the danger of becoming obsessed with material possessions and superficial success. The novel satirizes the absurdity of the grown-up world, where people are preoccupied with trivial matters. This theme resonates with modern society, where materialism and consumerism have reached unprecedented levels. The Little Prince\'s message encourages us to reassess our priorities and focus on what truly matters in life, such as personal growth, relationships, and self-awareness.\n\nBody Paragraph 3: The Power of Vulnerability and Emotional Intelligence\nThe Little Prince emphasizes the importance of vulnerability and emotional intelligence. Throughout the story, the prince displays a level of emotional intelligence that is both refreshing and thought-provoking. He is not afraid to express his feelings, admit his mistakes, or show his love for others. This message is particularly relevant in today\'s world, where emotional intelligence and mental health are increasingly recognized as essential components of a fulfilling life. By embracing vulnerability, we can build stronger connections and foster a deeper understanding of ourselves and others.\n\nConclusion:\nIn conclusion, The Little Prince remains a topical and powerful work that delivers a timeless message for modern life. Its exploration of authentic relationships, the dangers of materialism and superficiality, and the power of vulnerability and emotional intelligence are as relevant today as they were when the book was first published. By embracing the wisdom of The Little Prince, we can better navigate our complex, fast-paced world and lead more meaningful, fulfilling lives.', response_metadata={'token_usage': {'prompt_tokens': 72, 'total_tokens': 1216, 'completion_tokens': 1144}, 'model_name': 'accounts/fireworks/models/mixtral-8x7b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run-8ccbedb3-0c09-4e50-b7aa-fbb233bf4c8b-0')}<br>---<br>{'reflect': HumanMessage(content='Your essay on "The Little Prince: A Timeless Message for Modern Life" is well-written, engaging, and thought-provoking. You have done an excellent job of identifying and analyzing the topical themes of the novel and connecting them to contemporary issues. Here are some recommendations to further enhance your essay:\n\n1. Length: While your essay is well-structured and coherent, consider expanding each body paragraph to provide more in-depth analysis. Aim for a minimum of 4-5 developed sentences per paragraph to ensure a thorough exploration of each theme.\n\n2. Depth: To add depth to your essay, consider incorporating specific examples from the novel to support your arguments. For instance, when discussing the importance of authentic relationships, provide a quote or two from the story that illustrates this theme. This will strengthen your argument and demonstrate your understanding of the text.\n\n3. Style: Vary your sentence structure to create a more engaging reading experience. Mix short and long sentences, and use rhetorical questions or transitions to guide the reader through your essay.\n\n4. Recommendation: In your conclusion, consider offering a recommendation or suggestion for applying the lessons from The Little Prince in modern life. This could be a personal anecdote, a current event, or a broader cultural observation that connects the novel\'s themes to contemporary society.\n\n5. Revised Essay: If you decide to revise your essay, consider the following title: "Embracing Vulnerability and Authenticity: The Little Prince\'s Timeless Message for Modern Life." This title better reflects the focus of your essay and highlights the importance of vulnerability and emotional intelligence.\n\nOverall, your essay is engaging and thoughtful. With a few adjustments to length, depth, and style, it can become an even more powerful exploration of the topicality of The Little Prince and its message in modern life.', id='9143f3d4-c27b-44c0-bac0-1e476db7ad4d')}<br>---<br>{'generate': AIMessage(content='Title: Embracing Vulnerability and Authenticity: The Little Prince\'s Timeless Message for Modern Life\n\nIntroduction:\nAntoine de Saint-Exupéry\'s "The Little Prince" is a timeless novella that has captured the hearts of millions since its publication in 1943. Despite the passage of over seven decades, the story remains incredibly relevant and topical in modern life. This essay explores the novel\'s themes and how they continue to resonate with people in the contemporary world, focusing on the importance of authentic relationships, the dangers of materialism and superficiality, and the power of vulnerability and emotional intelligence.\n\nBody Paragraph 1: The Importance of Authentic Relationships\nThe Little Prince teaches us about the significance of authentic relationships in our lives. In the story, the prince meets various inhabitants of other planets, each representing a different aspect of adult existence. For instance, the king, the vain man, and the businessman symbolize the superficiality of many adult relationships. However, the fox stands out as a symbol of genuine connections. The fox tells the prince, "One sees clearly only with the heart. Anything essential is invisible to the eyes" (Saint-Exupéry, 1943, p. 65). This quote emphasizes the value of emotional connections and authentic relationships, which are as crucial today as they were in the prince\'s universe.\n\nBody Paragraph 2: The Dangers of Materialism and Superficiality\nAnother timely message from The Little Prince is the danger of becoming obsessed with material possessions and superficial success. The novel satirizes the absurdity of the grown-up world, where people are preoccupied with trivial matters. For example, the businessman believes his purpose is to count stars to "own" them, illustrating the futility of materialism. This theme resonates with modern society, where materialism and consumerism have reached unprecedented levels. The Little Prince\'s message encourages us to reassess our priorities and focus on what truly matters in life, such as personal growth, relationships, and self-awareness.\n\nBody Paragraph 3: The Power of Vulnerability and Emotional Intelligence\nThe Little Prince emphasizes the importance of vulnerability and emotional intelligence. Throughout the story, the prince displays a level of emotional intelligence that is both refreshing and thought-provoking. He is not afraid to express his feelings, admit his mistakes, or show his love for others. This message is particularly relevant in today\'s world, where emotional intelligence and mental health are increasingly recognized as essential components of a fulfilling life. By embracing vulnerability, we can build stronger connections and foster a deeper understanding of ourselves and others.\n\nConclusion:\nIn conclusion, The Little Prince remains a topical and powerful work that delivers a timeless message for modern life. Its exploration of authentic relationships, the dangers of materialism and superficiality, and the power of vulnerability and emotional intelligence are as relevant today as they were when the book was first published. Embracing the wisdom of The Little Prince means acknowledging the importance of genuine connections, reassessing our priorities, and fostering emotional intelligence in our daily lives. By doing so, we can better navigate our complex, fast-paced world and lead more meaningful, fulfilling lives.', response_metadata={'token_usage': {'prompt_tokens': 1627, 'total_tokens': 2351, 'completion_tokens': 724}, 'model_name': 'accounts/fireworks/models/mixtral-8x7b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run-753eb78a-8493-42ac-ad50-ba0063cf2686-0')}<br>---<br>{'reflect': HumanMessage(content='Your revised essay, "Embracing Vulnerability and Authenticity: The Little Prince\'s Timeless Message for Modern Life," is well-structured and engaging. You have done an excellent job incorporating specific examples from the novel to support your arguments and connecting the themes to contemporary issues. Here are some suggestions for further improvement:\n\n1. Depth: Consider adding more depth to your analysis by discussing the potential consequences of not embracing the lessons from The Little Prince. For instance, what might happen if we continue to prioritize material possessions and superficial success over personal growth and relationships?\n\n2. Style: Experiment with varying your sentence structure and incorporating rhetorical questions to create a more engaging reading experience. For example, in your first body paragraph, you could ask, "What can we learn from the fox\'s wisdom about the significance of authentic relationships?"\n\n3. Recommendation: In your conclusion, consider offering a specific recommendation or suggestion for applying the lessons from The Little Prince in modern life. For instance, you could encourage readers to practice active listening or express gratitude to foster authentic relationships.\n\n4. Citation: Ensure that your citation is formatted correctly according to the required citation style (e.g., MLA, APA, or Chicago). In your current essay, the citation for the quote from the fox is formatted as (Saint-Exupéry, 1943, p. 65), which may not be appropriate for all citation styles.\n\nOverall, your revised essay is engaging, thoughtful, and well-supported. With a few adjustments to depth, style, and recommendations, it can become an even more powerful exploration of the topicality of The Little Prince and its message in modern life.', id='c709ef93-064f-469f-8234-99cdd4649a27')}<br>---<br>{'generate': AIMessage(content='Title: Embracing Vulnerability and Authenticity: The Little Prince\'s Timeless Message for Modern Life\n\nIntroduction:\nAntoine de Saint-Exupéry\'s "The Little Prince" is a timeless novella that has captured the hearts of millions since its publication in 1943. Despite the passage of over seven decades, the story remains incredibly relevant and topical in modern life. This essay explores the novel\'s themes and how they continue to resonate with people in the contemporary world, focusing on the importance of authentic relationships, the dangers of materialism and superficiality, and the power of vulnerability and emotional intelligence.\n\nBody Paragraph 1: The Importance of Authentic Relationships\nWhat can we learn from the fox\'s wisdom about the significance of authentic relationships? In the story, the fox tells the prince, "One sees clearly only with the heart. Anything essential is invisible to the eyes" (Saint-Exupéry, 1943, p. 65). Neglecting authentic relationships can lead to feelings of isolation, loneliness, and disconnection in today\'s fast-paced, technology-driven world. By prioritizing genuine connections, we can foster a sense of community, belonging, and emotional well-being.\n\nBody Paragraph 2: The Dangers of Materialism and Superficiality\nAnother timely message from The Little Prince is the danger of becoming obsessed with material possessions and superficial success. The novel satirizes the absurdity of the grown-up world, where people are preoccupied with trivial matters. For example, the businessman believes his purpose is to count stars to "own" them, illustrating the futility of materialism. Prioritizing material possessions and superficial success over personal growth and relationships can lead to feelings of emptiness, dissatisfaction, and a lack of purpose in life.\n\nBody Paragraph 3: The Power of Vulnerability and Emotional Intelligence\nThe Little Prince emphasizes the importance of vulnerability and emotional intelligence. Throughout the story, the prince displays a level of emotional intelligence that is both refreshing and thought-provoking. By embracing vulnerability, we can build stronger connections, communicate more effectively, and foster a deeper understanding of ourselves and others. Neglecting vulnerability and emotional intelligence can lead to misunderstandings, conflict, and damaged relationships.\n\nConclusion:\nIn conclusion, The Little Prince remains a topical and powerful work that delivers a timeless message for modern life. To apply the lessons from The Little Prince in our daily lives, consider practicing active listening, expressing gratitude, and nurturing authentic relationships. By doing so, we can better navigate our complex, fast-paced world and lead more meaningful, fulfilling lives.\n\nReference:\nSaint-Exupéry, A. de. (1943). The Little Prince. Reynal &amp; Hitchcock.', response_metadata={'token_usage': {'prompt_tokens': 2740, 'total_tokens': 3380, 'completion_tokens': 640}, 'model_name': 'accounts/fireworks/models/mixtral-8x7b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run-ba992864-5a1b-487d-81a3-a52f74f900ce-0')}<br>---<br>{'reflect': HumanMessage(content='Your revised essay, "Embracing Vulnerability and Authenticity: The Little Prince\'s Timeless Message for Modern Life," is well-structured, engaging, and thought-provoking. You have done an excellent job incorporating specific examples from the novel to support your arguments and connecting the themes to contemporary issues. Your essay now includes a clear recommendation for applying the lessons from The Little Prince in modern life.\n\nTo further enhance your essay, consider the following suggestions:\n\n1. Depth: You could add more depth to your analysis by discussing the potential consequences of not embracing the lessons from The Little Prince. For instance, what might happen if we continue to prioritize material possessions and superficial success over personal growth and relationships?\n\n2. Style: Experiment with varying your sentence structure and incorporating rhetorical questions to create a more engaging reading experience. For example, in your first body paragraph, you could ask, "What insights does the fox offer about the significance of authentic relationships?"\n\n3. Quotations: Ensure that your quotations are integrated smoothly into your sentences and are properly formatted according to the required citation style (e.g., MLA, APA, or Chicago).\n\nOverall, your revised essay is engaging, thoughtful, and well-supported. By addressing the importance of authentic relationships, the dangers of materialism and superficiality, and the power of vulnerability and emotional intelligence, you have created a compelling exploration of the topicality of The Little Prince and its message in modern life.', id='deaccdc6-3b38-413e-b996-bb67b90f5e41')}<br>---<br>{'generate': AIMessage(content='Title: Embracing Vulnerability and Authenticity: The Little Prince\'s Timeless Message for Modern Life\n\nIntroduction:\nAntoine de Saint-Exupéry\'s "The Little Prince" is a timeless novella that has captured the hearts of millions since its publication in 1943. Despite the passage of over seven decades, the story remains incredibly relevant and topical in modern life. This essay explores the novel\'s themes and how they continue to resonate with people in the contemporary world, focusing on the importance of authentic relationships, the dangers of materialism and superficiality, and the power of vulnerability and emotional intelligence.\n\nBody Paragraph 1: The Importance of Authentic Relationships\nWhat insights does the fox offer about the significance of authentic relationships? In the story, the fox tells the prince, "One sees clearly only with the heart. Anything essential is invisible to the eyes" (Saint-Exupéry, 1943, p. 65). Neglecting authentic relationships can lead to feelings of isolation, loneliness, and disconnection in today\'s fast-paced, technology-driven world. By prioritizing genuine connections, we can foster a sense of community, belonging, and emotional well-being. Ignoring the importance of authentic relationships can result in increased loneliness, mental health issues, and a lack of empathy in society.\n\nBody Paragraph 2: The Dangers of Materialism and Superficiality\nAnother timely message from The Little Prince is the danger of becoming obsessed with material possessions and superficial success. The novel satirizes the absurdity of the grown-up world, where people are preoccupied with trivial matters. For example, the businessman believes his purpose is to count stars to "own" them, illustrating the futility of materialism. Prioritizing material possessions and superficial success over personal growth and relationships can lead to feelings of emptiness, dissatisfaction, and a lack of purpose in life. Continuing to prioritize materialism and superficiality can result in increased inequality, environmental degradation, and a loss of meaning and purpose in our lives.\n\nBody Paragraph 3: The Power of Vulnerability and Emotional Intelligence\nThe Little Prince emphasizes the importance of vulnerability and emotional intelligence. Throughout the story, the prince displays a level of emotional intelligence that is both refreshing and thought-provoking. By embracing vulnerability, we can build stronger connections, communicate more effectively, and foster a deeper understanding of ourselves and others. Neglecting vulnerability and emotional intelligence can lead to misunderstandings, conflict, and damaged relationships. Failing to cultivate vulnerability and emotional intelligence can result in strained relationships, decreased empathy, and an inability to navigate complex emotional situations.\n\nConclusion:\nIn conclusion, The Little Prince remains a topical and powerful work that delivers a timeless message for modern life. To apply the lessons from The Little Prince in our daily lives, consider practicing active listening, expressing gratitude, and nurturing authentic relationships. By doing so, we can better navigate our complex, fast-paced world and lead more meaningful, fulfilling lives.\n\nReference:\nSaint-Exupéry, A. de. (1943). The Little Prince. Reynal &amp; Hitchcock.', response_metadata={'token_usage': {'prompt_tokens': 3718, 'total_tokens': 4448, 'completion_tokens': 730}, 'model_name': 'accounts/fireworks/models/mixtral-8x7b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run-6665a113-91c9-4bef-b9b1-3cfc9f33b591-0')}<br>---<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(event[<span class="hljs-string">'generate'</span>].content)<br></code></pre></td></tr></table></figure><p>输出</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs text">Title: Embracing Vulnerability and Authenticity: The Little Prince's Timeless Message for Modern Life<br><br>Introduction:<br>Antoine de Saint-Exupéry's "The Little Prince" is a timeless novella that has captured the hearts of millions since its publication in 1943. Despite the passage of over seven decades, the story remains incredibly relevant and topical in modern life. This essay explores the novel's themes and how they continue to resonate with people in the contemporary world, focusing on the importance of authentic relationships, the dangers of materialism and superficiality, and the power of vulnerability and emotional intelligence.<br><br>Body Paragraph 1: The Importance of Authentic Relationships<br>What insights does the fox offer about the significance of authentic relationships? In the story, the fox tells the prince, "One sees clearly only with the heart. Anything essential is invisible to the eyes" (Saint-Exupéry, 1943, p. 65). Neglecting authentic relationships can lead to feelings of isolation, loneliness, and disconnection in today's fast-paced, technology-driven world. By prioritizing genuine connections, we can foster a sense of community, belonging, and emotional well-being. Ignoring the importance of authentic relationships can result in increased loneliness, mental health issues, and a lack of empathy in society.<br><br>Body Paragraph 2: The Dangers of Materialism and Superficiality<br>Another timely message from The Little Prince is the danger of becoming obsessed with material possessions and superficial success. The novel satirizes the absurdity of the grown-up world, where people are preoccupied with trivial matters. For example, the businessman believes his purpose is to count stars to "own" them, illustrating the futility of materialism. Prioritizing material possessions and superficial success over personal growth and relationships can lead to feelings of emptiness, dissatisfaction, and a lack of purpose in life. Continuing to prioritize materialism and superficiality can result in increased inequality, environmental degradation, and a loss of meaning and purpose in our lives.<br><br>Body Paragraph 3: The Power of Vulnerability and Emotional Intelligence<br>The Little Prince emphasizes the importance of vulnerability and emotional intelligence. Throughout the story, the prince displays a level of emotional intelligence that is both refreshing and thought-provoking. By embracing vulnerability, we can build stronger connections, communicate more effectively, and foster a deeper understanding of ourselves and others. Neglecting vulnerability and emotional intelligence can lead to misunderstandings, conflict, and damaged relationships. Failing to cultivate vulnerability and emotional intelligence can result in strained relationships, decreased empathy, and an inability to navigate complex emotional situations.<br><br>Conclusion:<br>In conclusion, The Little Prince remains a topical and powerful work that delivers a timeless message for modern life. To apply the lessons from The Little Prince in our daily lives, consider practicing active listening, expressing gratitude, and nurturing authentic relationships. By doing so, we can better navigate our complex, fast-paced world and lead more meaningful, fulfilling lives.<br><br>Reference:<br>Saint-Exupéry, A. de. (1943). The Little Prince. Reynal &amp; Hitchcock.<br></code></pre></td></tr></table></figure><p>LangSmith流程展示：</p><p><img src="/images/LangSmith_Reflect.png" srcset="/img/loading.gif" lazyload></p>
        </div>
      </div>
    </div>
<p>这种简单类型的<code>Reflect</code>有时可以通过让大型语言模型（LLM）多次尝试优化其输出，并通过让<code>Reflector</code>节点在评判输出时采用不同的角色来提高性能。然而，由于<code>Reflect</code>步骤没有基于任何外部过程，最终结果可能并不比原始结果有显著的改进。</p>
<h3 id="reflexion">2. Reflexion</h3>
<ul>
<li><strong><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.11366">Reflexion</a></strong>：一种通过口头反馈和自我反思学习的结构。</li>
<li><strong>特点</strong>：代理明确评判每个响应，并将评判基于外部数据，生成引用，明确指出生成响应中多余和缺失的部分。这使得反思的内容更具建设性，并更好地引导生成器响应反馈。</li>
<li><strong>循环逻辑</strong>：可以在固定步骤后停止，也可将循环决策交给<code>Reflect LLM</code>。</li>
</ul>
<p>Reflexion Agent 流程概览：</p>
<figure>
<img src="/images/reflexion.png" srcset="/img/loading.gif" lazyload alt="Reflexion Actor Overview">
<figcaption aria-hidden="true">Reflexion Actor Overview</figcaption>
</figure>
<p>对于每一步，<code>Responder</code>的任务是生成一个响应，同时以搜索查询的形式进行额外的操作。然后，<code>Revisor</code>对当前状态进行反思。</p>

    <div class="fold">
      <div class="fold-title fold-info collapsed" data-toggle="collapse" href="#collapse-9ef711e9" role="button" aria-expanded="false" aria-controls="collapse-9ef711e9">
        <div class="fold-arrow">▶</div>LangGraph代码示例
      </div>
      <div class="fold-collapse collapse" id="collapse-9ef711e9">
        <div class="fold-content">
          <p><strong>Tool</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain_community.tools.tavily_search <span class="hljs-keyword">import</span> TavilySearchResults<br><span class="hljs-keyword">from</span> langchain_community.utilities.tavily_search <span class="hljs-keyword">import</span> TavilySearchAPIWrapper<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><span class="hljs-keyword">import</span> json<br><br><br><span class="hljs-keyword">from</span> langchain.output_parsers.openai_tools <span class="hljs-keyword">import</span> (<br>    JsonOutputToolsParser,<br>    PydanticToolsParser,<br>)<br><span class="hljs-keyword">from</span> langchain_core.messages <span class="hljs-keyword">import</span> AIMessage, BaseMessage, HumanMessage, ToolMessage<br><span class="hljs-keyword">from</span> langgraph.prebuilt.tool_executor <span class="hljs-keyword">import</span> ToolExecutor, ToolInvocation<br><br><br>search = TavilySearchAPIWrapper()<br>tavily_tool = TavilySearchResults(api_wrapper=search, max_results=<span class="hljs-number">5</span>)<br><br><br>tool_executor = ToolExecutor([tavily_tool])<br>parser = JsonOutputToolsParser(return_id=<span class="hljs-literal">True</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">execute_tools</span>(<span class="hljs-params">state: <span class="hljs-type">List</span>[BaseMessage]</span>) -&gt; <span class="hljs-type">List</span>[BaseMessage]:<br>    tool_invocation: AIMessage = state[-<span class="hljs-number">1</span>]<br>    parsed_tool_calls = parser.invoke(tool_invocation)<br>    ids = []<br>    tool_invocations = []<br>    <span class="hljs-keyword">for</span> parsed_call <span class="hljs-keyword">in</span> parsed_tool_calls:<br>        <span class="hljs-keyword">for</span> query <span class="hljs-keyword">in</span> parsed_call[<span class="hljs-string">"args"</span>][<span class="hljs-string">"search_queries"</span>]:<br>            tool_invocations.append(<br>                ToolInvocation(<br>                    <span class="hljs-comment"># We only have this one for now. Would want to map it</span><br>                    <span class="hljs-comment"># if we change</span><br>                    tool=<span class="hljs-string">"tavily_search_results_json"</span>,<br>                    tool_input=query,<br>                )<br>            )<br>            ids.append(parsed_call[<span class="hljs-string">"id"</span>])<br><br>    outputs = tool_executor.batch(tool_invocations)<br>    outputs_map = defaultdict(<span class="hljs-built_in">dict</span>)<br>    <span class="hljs-keyword">for</span> id_, output, invocation <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(ids, outputs, tool_invocations):<br>        outputs_map[id_][invocation.tool_input] = output<br><br>    <span class="hljs-keyword">return</span> [<br>        ToolMessage(content=json.dumps(query_outputs), tool_call_id=id_)<br>        <span class="hljs-keyword">for</span> id_, query_outputs <span class="hljs-keyword">in</span> outputs_map.items()<br>    ]<br></code></pre></td></tr></table></figure><p><strong>Responder</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> datetime<br><br><span class="hljs-keyword">from</span> langchain_core.prompts <span class="hljs-keyword">import</span> ChatPromptTemplate, MessagesPlaceholder<br><span class="hljs-keyword">from</span> langchain_core.pydantic_v1 <span class="hljs-keyword">import</span> BaseModel, Field, ValidationError<br><span class="hljs-keyword">from</span> langchain_openai <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> langsmith <span class="hljs-keyword">import</span> traceable<br><br>actor_prompt_template = ChatPromptTemplate.from_messages(<br>    [<br>        (<br>            <span class="hljs-string">"system"</span>,<br>            <span class="hljs-string">"""You are expert researcher.</span><br><span class="hljs-string">Current time: {time}</span><br><span class="hljs-string"></span><br><span class="hljs-string">1. {first_instruction}</span><br><span class="hljs-string">2. Reflect and critique your answer. Be severe to maximize improvement.</span><br><span class="hljs-string">3. Recommend search queries to research information and improve your answer."""</span>,<br>        ),<br>        MessagesPlaceholder(variable_name=<span class="hljs-string">"messages"</span>),<br>        (<span class="hljs-string">"system"</span>, <span class="hljs-string">"Answer the user's question above using the required format."</span>),<br>    ]<br>).partial(<br>    time=<span class="hljs-keyword">lambda</span>: datetime.datetime.now().isoformat(),<br>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Reflection</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    missing: <span class="hljs-built_in">str</span> = Field(description=<span class="hljs-string">"Critique of what is missing."</span>)<br>    superfluous: <span class="hljs-built_in">str</span> = Field(description=<span class="hljs-string">"Critique of what is superfluous"</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">AnswerQuestion</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    <span class="hljs-string">"""Answer the question."""</span><br><br>    answer: <span class="hljs-built_in">str</span> = Field(description=<span class="hljs-string">"~250 word detailed answer to the question."</span>)<br>    reflection: Reflection = Field(description=<span class="hljs-string">"Your reflection on the initial answer."</span>)<br>    search_queries: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>] = Field(<br>        description=<span class="hljs-string">"1-3 search queries for researching improvements to address the critique of your current answer."</span><br>    )<br><br><br>llm = ChatOpenAI(model=<span class="hljs-string">"gpt-4-turbo"</span>)<br>initial_answer_chain = actor_prompt_template.partial(<br>    first_instruction=<span class="hljs-string">"Provide a detailed ~250 word answer."</span><br>) | llm.bind_tools(tools=[AnswerQuestion], tool_choice=<span class="hljs-string">"AnswerQuestion"</span>)<br>validator = PydanticToolsParser(tools=[AnswerQuestion])<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResponderWithRetries</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, runnable, validator</span>):<br>        <span class="hljs-variable language_">self</span>.runnable = runnable<br>        <span class="hljs-variable language_">self</span>.validator = validator<br><br><span class="hljs-meta">    @traceable</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">respond</span>(<span class="hljs-params">self, state: <span class="hljs-type">List</span>[BaseMessage]</span>):<br>        response = []<br>        <span class="hljs-keyword">for</span> attempt <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>            <span class="hljs-keyword">try</span>:<br>                response = <span class="hljs-variable language_">self</span>.runnable.invoke({<span class="hljs-string">"messages"</span>: state})<br>                <span class="hljs-variable language_">self</span>.validator.invoke(response)<br>                <span class="hljs-keyword">return</span> response<br>            <span class="hljs-keyword">except</span> ValidationError <span class="hljs-keyword">as</span> e:<br>                state = state + [HumanMessage(content=<span class="hljs-built_in">repr</span>(e))]<br>        <span class="hljs-keyword">return</span> response<br>    <br>first_responder = ResponderWithRetries(<br>    runnable=initial_answer_chain, validator=validator<br>)<br></code></pre></td></tr></table></figure><p><strong>Revision</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python">revise_instructions = <span class="hljs-string">"""Revise your previous answer using the new information.</span><br><span class="hljs-string">    - You should use the previous critique to add important information to your answer.</span><br><span class="hljs-string">        - You MUST include numerical citations in your revised answer to ensure it can be verified.</span><br><span class="hljs-string">        - Add a "References" section to the bottom of your answer (which does not count towards the word limit). In form of:</span><br><span class="hljs-string">            - [1] https://example.com</span><br><span class="hljs-string">            - [2] https://example.com</span><br><span class="hljs-string">    - You should use the previous critique to remove superfluous information from your answer and make SURE it is not more than 250 words.</span><br><span class="hljs-string">"""</span><br><br><br><span class="hljs-comment"># Extend the initial answer schema to include references.</span><br><span class="hljs-comment"># Forcing citation in the model encourages grounded responses</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ReviseAnswer</span>(<span class="hljs-title class_ inherited__">AnswerQuestion</span>):<br>    <span class="hljs-string">"""Revise your original answer to your question."""</span><br><br>    references: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>] = Field(<br>        description=<span class="hljs-string">"Citations motivating your updated answer."</span><br>    )<br><br><br>revision_chain = actor_prompt_template.partial(<br>    first_instruction=revise_instructions<br>) | llm.bind_tools(tools=[ReviseAnswer], tool_choice=<span class="hljs-string">"ReviseAnswer"</span>)<br>revision_validator = PydanticToolsParser(tools=[ReviseAnswer])<br><br>revisor = ResponderWithRetries(runnable=revision_chain, validator=revision_validator)<br></code></pre></td></tr></table></figure><p><strong>构造Graph</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langgraph.graph <span class="hljs-keyword">import</span> END, MessageGraph<br><br>MAX_ITERATIONS = <span class="hljs-number">5</span><br>builder = MessageGraph()<br>builder.add_node(<span class="hljs-string">"draft"</span>, first_responder.respond)<br>builder.add_node(<span class="hljs-string">"execute_tools"</span>, execute_tools)<br>builder.add_node(<span class="hljs-string">"revise"</span>, revisor.respond)<br><span class="hljs-comment"># draft -&gt; execute_tools</span><br>builder.add_edge(<span class="hljs-string">"draft"</span>, <span class="hljs-string">"execute_tools"</span>)<br><span class="hljs-comment"># execute_tools -&gt; revise</span><br>builder.add_edge(<span class="hljs-string">"execute_tools"</span>, <span class="hljs-string">"revise"</span>)<br><br><span class="hljs-comment"># Define looping logic:</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_get_num_iterations</span>(<span class="hljs-params">state: <span class="hljs-type">List</span>[BaseMessage]</span>):<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> state[::-<span class="hljs-number">1</span>]:<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(m, (ToolMessage, AIMessage)):<br>            <span class="hljs-keyword">break</span><br>        i += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> i<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">event_loop</span>(<span class="hljs-params">state: <span class="hljs-type">List</span>[BaseMessage]</span>) -&gt; <span class="hljs-built_in">str</span>:<br>    <span class="hljs-comment"># in our case, we'll just stop after N plans</span><br>    num_iterations = _get_num_iterations(state)<br>    <span class="hljs-keyword">if</span> num_iterations &gt; MAX_ITERATIONS:<br>        <span class="hljs-keyword">return</span> END<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">"execute_tools"</span><br><br><br><span class="hljs-comment"># revise -&gt; execute_tools OR end</span><br>builder.add_conditional_edges(<span class="hljs-string">"revise"</span>, event_loop)<br>builder.set_entry_point(<span class="hljs-string">"draft"</span>)<br>graph = builder.<span class="hljs-built_in">compile</span>()<br></code></pre></td></tr></table></figure><p><strong>执行</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">events = graph.stream(<br>    [HumanMessage(content=<span class="hljs-string">"How should we handle the climate crisis?"</span>)]<br>)<br><span class="hljs-keyword">for</span> i, step <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(events):<br>    node, output = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(step.items()))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"## <span class="hljs-subst">{i+<span class="hljs-number">1</span>}</span>. <span class="hljs-subst">{node}</span>"</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">str</span>(output)[:<span class="hljs-number">100</span>] + <span class="hljs-string">" ..."</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"---"</span>)<br></code></pre></td></tr></table></figure><p>输出</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs text">## 1. draft<br>content='' additional_kwargs={'tool_calls': [{'id': 'call_zsSoRPEYQbdMCfTFE6Zt3yWZ', 'function': {'a ...<br>---<br>## 2. execute_tools<br>[ToolMessage(content='{"role of international cooperation in climate crisis": [{"url": "https://www. ...<br>---<br>## 3. revise<br>content='' additional_kwargs={'tool_calls': [{'id': 'call_haETlmZsvMvTDgvVnoX7PF8B', 'function': {'a ...<br>---<br>## 4. execute_tools<br>[ToolMessage(content='{"effective climate change policies 2024": [{"url": "https://www.nature.com/ar ...<br>---<br>## 5. revise<br>content='' additional_kwargs={'tool_calls': [{'id': 'call_ftYfUYHV6J6PQP56lTvAgQAa', 'function': {'a ...<br>---<br>## 6. execute_tools<br>[ToolMessage(content='{"global climate agreements effectiveness": [{"url": "https://www.climatereali ...<br>---<br>## 7. revise<br>content='' additional_kwargs={'tool_calls': [{'id': 'call_PgTBJqyP5dbBEANOpRIcLaPg', 'function': {'a ...<br>---<br></code></pre></td></tr></table></figure><p><strong>结果</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(parser.invoke(step[<span class="hljs-string">'revise'</span>])[-<span class="hljs-number">1</span>][<span class="hljs-string">"args"</span>][<span class="hljs-string">"answer"</span>])<br></code></pre></td></tr></table></figure><p>输出</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs markdown">Addressing the climate crisis requires a comprehensive and multifaceted approach. Here are several key strategies:<br><br><span class="hljs-bullet">1.</span> <span class="hljs-strong">**Transition to Renewable Energy:**</span> Shifting from fossil fuels to renewable energy sources like solar, wind, and hydroelectric is crucial. This reduces greenhouse gas emissions, which are primary drivers of climate change [1].<br><br><span class="hljs-bullet">2.</span> <span class="hljs-strong">**Enhance Energy Efficiency:**</span> Improving energy efficiency in buildings, vehicles, and industries can significantly reduce energy consumption and emissions [1].<br><br><span class="hljs-bullet">3.</span> <span class="hljs-strong">**Carbon Pricing:**</span> Implementing carbon pricing mechanisms, such as carbon taxes or cap-and-trade systems, incentivizes companies to reduce their carbon footprint [1].<br><br><span class="hljs-bullet">4.</span> <span class="hljs-strong">**Conservation and Reforestation:**</span> Protecting forests and other ecosystems can absorb CO2 from the atmosphere. Reforestation and afforestation efforts are also vital, as they sequester atmospheric carbon and enhance biodiversity [1].<br><br><span class="hljs-bullet">5.</span> <span class="hljs-strong">**Climate Adaptation Measures:**</span> Developing infrastructure and policies to adapt to climate impacts, like rising sea levels and increased weather variability, is essential. This includes building flood defenses, creating drought-resistant crops, and improving water management systems [1].<br><br><span class="hljs-bullet">6.</span> <span class="hljs-strong">**International Cooperation:**</span> Effective management of the climate crisis requires global cooperation. Agreements like the Paris Agreement are essential as they engage countries in a united effort to curb emissions and adapt to climate changes [2].<br><br><span class="hljs-bullet">7.</span> <span class="hljs-strong">**Education and Public Awareness:**</span> Raising awareness and educating the public about the impacts of climate change and the importance of mitigation efforts is crucial. This can drive behavioral changes and support for policy measures aimed at combating climate change [3].<br></code></pre></td></tr></table></figure><p>LangSmith流程展示：</p><p><img src="/images/LangSmith_Reflexion.png" srcset="/img/loading.gif" lazyload></p>
        </div>
      </div>
    </div>
<p>这种Agent能够有效地使用明确的反思和基于网络搜索的内容来提高最终响应的质量。然而，它过程比较固定，如果它犯了一个错误，那个错误可能会影响后续的决策。</p>
<h3 id="language-agent-tree-searchlats">3. Language Agent Tree
Search(LATS)</h3>
<p><strong><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.04406">LATS</a></strong>：一种通用的LLM
Agent搜索算法，它结合了反思/评估和搜索（特别是蒙特卡洛树搜索），以实现比类似技术如ReACT、Reflexion甚至思维树更好的整体任务性能。它采用标准的强化学习（RL）任务框架，将RL
Agents、价值函数和优化器全部替换为对LLM的调用。这可以帮助Agent适应和解决复杂任务，避免陷入重复循环。</p>
<p>LATS 流程概览：</p>
<p><img src="/images/lats.png" srcset="/img/loading.gif" lazyload></p>
<p><strong>搜索主要步骤</strong>： 1.
<strong>Select(选择)</strong>：依据第二步累计奖励来挑选挑选最佳的下一步
action，如果找到了解决方案或达到了最大搜索深度则返回响应，否则继续搜索
2. <strong>Expand and simulate(扩展和模拟)</strong>: 生成N个可能的
action，并行执行它们。 3. <strong>Reflect +
evaluate(反思+评估)</strong>：观察这些action的结果，并根据反思（以及可能的外部反馈）给决策打分。
4.
<strong>Backpropagate(反向传播)</strong>：根据结果更新根轨迹的得分。</p>
<p>如果 Agent
通过高质量的环境奖励或可靠的反思得分反馈循环，搜索能够准确地区分不同的行动轨迹并选择最佳路径。然后，最终的轨迹可以保存到外部存储器中（或用于模型微调），以在未来改进模型。</p>
<p>Select步骤挑选最高上置信界限（UCT）的节点，这样可以在预期奖励（第一项）与探索新路径的激励（第二项）之间取得平衡。
​</p>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -3.294ex;" xmlns="http://www.w3.org/2000/svg" width="77.75ex" height="11.521ex" role="img" focusable="false" viewBox="0 -3636.5 34365.4 5092.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mstyle" transform="scale(2.07)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D448" d="M107 637Q73 637 71 641Q70 643 70 649Q70 673 81 682Q83 683 98 683Q139 681 234 681Q268 681 297 681T342 682T362 682Q378 682 378 672Q378 670 376 658Q371 641 366 638H364Q362 638 359 638T352 638T343 637T334 637Q295 636 284 634T266 623Q265 621 238 518T184 302T154 169Q152 155 152 140Q152 86 183 55T269 24Q336 24 403 69T501 205L552 406Q599 598 599 606Q599 633 535 637Q511 637 511 648Q511 650 513 660Q517 676 519 679T529 683Q532 683 561 682T645 680Q696 680 723 681T752 682Q767 682 767 672Q767 650 759 642Q756 637 737 637Q666 633 648 597Q646 592 598 404Q557 235 548 205Q515 105 433 42T263 -22Q171 -22 116 34T60 167V183Q60 201 115 421Q164 622 164 628Q164 635 107 637Z"></path></g><g data-mml-node="mi" transform="translate(767,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mi" transform="translate(1527,0)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g><g data-mml-node="mo" transform="translate(2508.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(3564.6,0)"><g data-mml-node="mrow" transform="translate(282,676)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(485,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1014,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(1312,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1884,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(485,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(830,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(1299,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1644,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(2005,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g><rect width="2674" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(6700.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mroot" transform="translate(7701,0)"><g><g data-mml-node="mfrac" transform="translate(1020,0)"><g data-mml-node="mrow" transform="translate(220,710)"><g data-mml-node="mi"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)"></path></g><g data-mml-node="mo" transform="translate(834,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(834,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1223,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(1726,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(2255,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2706,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(3172,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3772,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(4133,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mi" transform="translate(4577.7,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(5062.7,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5407.7,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(5876.7,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6221.7,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(6582.7,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(7051.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mrow" transform="translate(2703.3,-686)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(485,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(830,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(1299,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1644,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(2005,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g><rect width="7640.7" height="60" x="120" y="220"></rect></g></g><g data-mml-node="mstyle" transform="translate(232,692) scale(0.5)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g></g></g><g data-mml-node="mo" transform="translate(0,311)"><path data-c="221A" d="M424 -948Q422 -947 313 -434T202 80L170 31Q165 24 157 10Q137 -21 137 -21Q131 -16 124 -8L111 5L264 248L473 -720Q473 -717 727 359T983 1440Q989 1450 1001 1450Q1007 1450 1013 1445T1020 1433Q1020 1425 742 244T460 -941Q458 -950 439 -950H436Q424 -950 424 -948Z"></path></g><rect width="7880.7" height="124.2" x="1020" y="1636.8"></rect></g></g></g></g></svg></mjx-container></span></p>

    <div class="fold">
      <div class="fold-title fold-info collapsed" data-toggle="collapse" href="#collapse-a5bfb3c2" role="button" aria-expanded="false" aria-controls="collapse-a5bfb3c2">
        <div class="fold-arrow">▶</div>LangGraph代码示例
      </div>
      <div class="fold-collapse collapse" id="collapse-a5bfb3c2">
        <div class="fold-content">
          <p><strong>Graph State</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> annotations<br><span class="hljs-keyword">from</span> typing_extensions <span class="hljs-keyword">import</span> TypedDict<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Optional</span><br><span class="hljs-keyword">from</span> langchain_core.messages <span class="hljs-keyword">import</span> AIMessage, BaseMessage, HumanMessage, ToolMessage<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Node</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        messages: <span class="hljs-type">List</span>[BaseMessage],</span><br><span class="hljs-params">        reflection: Reflection,</span><br><span class="hljs-params">        parent: <span class="hljs-type">Optional</span>[Node] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-variable language_">self</span>.messages = messages<br>        <span class="hljs-variable language_">self</span>.parent = parent<br>        <span class="hljs-variable language_">self</span>.children = []<br>        <span class="hljs-variable language_">self</span>.value = <span class="hljs-number">0</span><br>        <span class="hljs-variable language_">self</span>.visits = <span class="hljs-number">0</span><br>        <span class="hljs-variable language_">self</span>.reflection = reflection<br>        <span class="hljs-variable language_">self</span>.depth = parent.depth + <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> parent <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br>        <span class="hljs-variable language_">self</span>._is_solved = reflection.found_solution <span class="hljs-keyword">if</span> reflection <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>._is_solved:<br>            <span class="hljs-variable language_">self</span>._mark_tree_as_solved()<br>        <span class="hljs-variable language_">self</span>.backpropagate(reflection.normalized_score)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__repr__</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-keyword">return</span> (<br>            <span class="hljs-string">f"&lt;Node value=<span class="hljs-subst">{self.value}</span>, visits=<span class="hljs-subst">{self.visits}</span>,"</span><br>            <span class="hljs-string">f" solution=<span class="hljs-subst">{self.messages}</span> reflection=<span class="hljs-subst">{self.reflection}</span>/&gt;"</span><br>        )<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">is_solved</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">"""If any solutions exist, we can end the search."""</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>._is_solved<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">is_terminal</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">not</span> <span class="hljs-variable language_">self</span>.children<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">best_child</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">"""Select the child with the highest UCT to search next."""</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-variable language_">self</span>.children:<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>        all_nodes = <span class="hljs-variable language_">self</span>._get_all_children()<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(all_nodes, key=<span class="hljs-keyword">lambda</span> child: child.upper_confidence_bound())<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">best_child_score</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">"""Return the child with the highest value."""</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-variable language_">self</span>.children:<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(<span class="hljs-variable language_">self</span>.children, key=<span class="hljs-keyword">lambda</span> child: <span class="hljs-built_in">int</span>(child.is_solved) * child.value)<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">height</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        <span class="hljs-string">"""Check for how far we've rolled out the tree."""</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.children:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> + <span class="hljs-built_in">max</span>([child.height <span class="hljs-keyword">for</span> child <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.children])<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">upper_confidence_bound</span>(<span class="hljs-params">self, exploration_weight=<span class="hljs-number">1.0</span></span>):<br>        <span class="hljs-string">"""Return the UCT score. This helps balance exploration vs. exploitation of a branch."""</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.parent <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">"Cannot obtain UCT from root node"</span>)<br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.visits == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.value<br>        <span class="hljs-comment"># Encourages exploitation of high-value trajectories</span><br>        average_reward = <span class="hljs-variable language_">self</span>.value / <span class="hljs-variable language_">self</span>.visits<br>        <span class="hljs-comment"># Encourages exploration of less-visited trajectories</span><br>        exploration_term = math.sqrt(math.log(<span class="hljs-variable language_">self</span>.parent.visits) / <span class="hljs-variable language_">self</span>.visits)<br>        <span class="hljs-keyword">return</span> average_reward + exploration_weight * exploration_term<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">backpropagate</span>(<span class="hljs-params">self, reward: <span class="hljs-built_in">float</span></span>):<br>        <span class="hljs-string">"""Update the score of this node and its parents."""</span><br>        node = <span class="hljs-variable language_">self</span><br>        <span class="hljs-keyword">while</span> node:<br>            node.visits += <span class="hljs-number">1</span><br>            node.value = (node.value * (node.visits - <span class="hljs-number">1</span>) + reward) / node.visits<br>            node = node.parent<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_messages</span>(<span class="hljs-params">self, include_reflections: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span></span>):<br>        <span class="hljs-keyword">if</span> include_reflections:<br>            <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.messages + [<span class="hljs-variable language_">self</span>.reflection.as_message()]<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.messages<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_trajectory</span>(<span class="hljs-params">self, include_reflections: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span></span>) -&gt; <span class="hljs-type">List</span>[BaseMessage]:<br>        <span class="hljs-string">"""Get messages representing this search branch."""</span><br>        messages = []<br>        node = <span class="hljs-variable language_">self</span><br>        <span class="hljs-keyword">while</span> node:<br>            messages.extend(<br>                node.get_messages(include_reflections=include_reflections)[::-<span class="hljs-number">1</span>]<br>            )<br>            node = node.parent<br>        <span class="hljs-comment"># Reverse the final back-tracked trajectory to return in the correct order</span><br>        <span class="hljs-keyword">return</span> messages[::-<span class="hljs-number">1</span>]  <span class="hljs-comment"># root solution, reflection, child 1, ...</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_get_all_children</span>(<span class="hljs-params">self</span>):<br>        all_nodes = []<br>        nodes = deque()<br>        nodes.append(<span class="hljs-variable language_">self</span>)<br>        <span class="hljs-keyword">while</span> nodes:<br>            node = nodes.popleft()<br>            all_nodes.extend(node.children)<br>            <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> node.children:<br>                nodes.append(n)<br>        <span class="hljs-keyword">return</span> all_nodes<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_best_solution</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">"""Return the best solution from within the current sub-tree."""</span><br>        all_nodes = [<span class="hljs-variable language_">self</span>] + <span class="hljs-variable language_">self</span>._get_all_children()<br>        best_node = <span class="hljs-built_in">max</span>(<br>            all_nodes,<br>            <span class="hljs-comment"># We filter out all non-terminal, non-solution trajectories</span><br>            key=<span class="hljs-keyword">lambda</span> node: <span class="hljs-built_in">int</span>(node.is_terminal <span class="hljs-keyword">and</span> node.is_solved) * node.value,<br>        )<br>        <span class="hljs-keyword">return</span> best_node<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_mark_tree_as_solved</span>(<span class="hljs-params">self</span>):<br>        parent = <span class="hljs-variable language_">self</span>.parent<br>        <span class="hljs-keyword">while</span> parent:<br>            parent._is_solved = <span class="hljs-literal">True</span><br>            parent = parent.parent<br>            <br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TreeState</span>(<span class="hljs-title class_ inherited__">TypedDict</span>):<br>    <span class="hljs-comment"># The full tree</span><br>    root: Node<br>    <span class="hljs-comment"># The original input</span><br>    <span class="hljs-built_in">input</span>: <span class="hljs-built_in">str</span><br></code></pre></td></tr></table></figure><p><strong>Tools And Model</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain_openai <span class="hljs-keyword">import</span> ChatOpenAI<br><br><span class="hljs-keyword">from</span> langchain_community.tools.tavily_search <span class="hljs-keyword">import</span> TavilySearchResults<br><span class="hljs-keyword">from</span> langchain_community.utilities.tavily_search <span class="hljs-keyword">import</span> TavilySearchAPIWrapper<br><br><span class="hljs-keyword">from</span> langgraph.prebuilt.tool_executor <span class="hljs-keyword">import</span> ToolExecutor, ToolInvocation<br><br>llm = ChatOpenAI(model=<span class="hljs-string">"gpt-4-turbo"</span>)<br><br>search = TavilySearchAPIWrapper()<br>tavily_tool = TavilySearchResults(api_wrapper=search, max_results=<span class="hljs-number">5</span>)<br>tools = [tavily_tool]<br>tool_executor = ToolExecutor(tools=tools)<br></code></pre></td></tr></table></figure><p><strong>Reflection</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> create_structured_output_runnable<br><span class="hljs-keyword">from</span> langchain.output_parsers.openai_tools <span class="hljs-keyword">import</span> (<br>    JsonOutputToolsParser,<br>    PydanticToolsParser,<br>)<br><span class="hljs-keyword">from</span> langchain_core.prompts <span class="hljs-keyword">import</span> ChatPromptTemplate, MessagesPlaceholder<br><span class="hljs-keyword">from</span> langchain_core.pydantic_v1 <span class="hljs-keyword">import</span> BaseModel, Field<br><span class="hljs-keyword">from</span> langchain_core.runnables <span class="hljs-keyword">import</span> chain <span class="hljs-keyword">as</span> as_runnable<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Reflection</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    reflections: <span class="hljs-built_in">str</span> = Field(<br>        description=<span class="hljs-string">"The critique and reflections on the sufficiency, superfluency,"</span><br>        <span class="hljs-string">" and general quality of the response"</span><br>    )<br>    score: <span class="hljs-built_in">int</span> = Field(<br>        description=<span class="hljs-string">"Score from 0-10 on the quality of the candidate response."</span>,<br>        gte=<span class="hljs-number">0</span>,<br>        lte=<span class="hljs-number">10</span>,<br>    )<br>    found_solution: <span class="hljs-built_in">bool</span> = Field(<br>        description=<span class="hljs-string">"Whether the response has fully solved the question or task."</span><br>    )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">as_message</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> HumanMessage(<br>            content=<span class="hljs-string">f"Reasoning: <span class="hljs-subst">{self.reflections}</span>\nScore: <span class="hljs-subst">{self.score}</span>"</span><br>        )<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normalized_score</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">float</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.score / <span class="hljs-number">10.0</span><br><br><br>prompt = ChatPromptTemplate.from_messages(<br>    [<br>        (<br>            <span class="hljs-string">"system"</span>,<br>            <span class="hljs-string">"Reflect and grade the assistant response to the user question below."</span>,<br>        ),<br>        (<span class="hljs-string">"user"</span>, <span class="hljs-string">"{input}"</span>),<br>        MessagesPlaceholder(variable_name=<span class="hljs-string">"candidate"</span>),<br>    ]<br>)<br><br>reflection_llm_chain = (<br>    prompt<br>    | llm.bind_tools(tools=[Reflection], tool_choice=<span class="hljs-string">"Reflection"</span>).with_config(<br>        run_name=<span class="hljs-string">"Reflection"</span><br>    )<br>    | PydanticToolsParser(tools=[Reflection])<br>)<br><br><br><span class="hljs-meta">@as_runnable</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">reflection_chain</span>(<span class="hljs-params">inputs</span>) -&gt; Reflection:<br>    tool_choices = reflection_llm_chain.invoke(inputs)<br>    reflection = tool_choices[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(inputs[<span class="hljs-string">"candidate"</span>][-<span class="hljs-number">1</span>], AIMessage):<br>        reflection.found_solution = <span class="hljs-literal">False</span><br>    <span class="hljs-keyword">return</span> reflection<br></code></pre></td></tr></table></figure><p><strong>Response</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><br><span class="hljs-keyword">from</span> langchain_core.prompt_values <span class="hljs-keyword">import</span> ChatPromptValue<br><span class="hljs-keyword">from</span> langchain_core.pydantic_v1 <span class="hljs-keyword">import</span> BaseModel, Field, ValidationError<br><span class="hljs-keyword">from</span> langchain_core.runnables <span class="hljs-keyword">import</span> RunnableConfig<br><br>prompt_template = ChatPromptTemplate.from_messages(<br>    [<br>        (<br>            <span class="hljs-string">"system"</span>,<br>            <span class="hljs-string">"You are an AI assistant."</span>,<br>        ),<br>        (<span class="hljs-string">"user"</span>, <span class="hljs-string">"{input}"</span>),<br>        MessagesPlaceholder(variable_name=<span class="hljs-string">"messages"</span>, optional=<span class="hljs-literal">True</span>),<br>    ]<br>)<br><br><br>initial_answer_chain = prompt_template | llm.bind_tools(tools=tools).with_config(<br>    run_name=<span class="hljs-string">"GenerateInitialCandidate"</span><br>)<br><br><br>parser = JsonOutputToolsParser(return_id=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p><strong>Graph Nodes</strong></p><p>Starting Node</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><br><br><span class="hljs-comment"># Define the node we will add to the graph</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_initial_response</span>(<span class="hljs-params">state: TreeState</span>) -&gt; <span class="hljs-built_in">dict</span>:<br>    <span class="hljs-string">"""Generate the initial candidate response."""</span><br>    res = initial_answer_chain.invoke({<span class="hljs-string">"input"</span>: state[<span class="hljs-string">"input"</span>]})<br>    parsed = parser.invoke(res)<br>    tool_responses = tool_executor.batch(<br>        [ToolInvocation(tool=r[<span class="hljs-string">"type"</span>], tool_input=r[<span class="hljs-string">"args"</span>]) <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> parsed]<br>    )<br>    output_messages = [res] + [<br>        ToolMessage(content=json.dumps(resp), tool_call_id=tool_call[<span class="hljs-string">"id"</span>])<br>        <span class="hljs-keyword">for</span> resp, tool_call <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(tool_responses, parsed)<br>    ]<br>    reflection = reflection_chain.invoke(<br>        {<span class="hljs-string">"input"</span>: state[<span class="hljs-string">"input"</span>], <span class="hljs-string">"candidate"</span>: output_messages}<br>    )<br>    root = Node(output_messages, reflection=reflection)<br>    <span class="hljs-keyword">return</span> {<br>        **state,<br>        <span class="hljs-string">"root"</span>: root,<br>    }<br></code></pre></td></tr></table></figure><p>Generation Node</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict, deque<br><span class="hljs-comment"># This generates N candidate values</span><br><span class="hljs-comment"># for a single input to sample actions from the environment</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_candidates</span>(<span class="hljs-params">messages: ChatPromptValue, config: RunnableConfig</span>):<br>    n = config[<span class="hljs-string">"configurable"</span>].get(<span class="hljs-string">"N"</span>, <span class="hljs-number">5</span>)<br>    bound_kwargs = llm.bind_tools(tools=tools).kwargs<br>    chat_result = llm.generate(<br>        [messages.to_messages()],<br>        n=n,<br>        callbacks=config[<span class="hljs-string">"callbacks"</span>],<br>        run_name=<span class="hljs-string">"GenerateCandidates"</span>,<br>        **bound_kwargs<br>    )<br>    <span class="hljs-keyword">return</span> [gen.message <span class="hljs-keyword">for</span> gen <span class="hljs-keyword">in</span> chat_result.generations[<span class="hljs-number">0</span>]]<br><br><br>expansion_chain = prompt_template | generate_candidates<br><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">expand</span>(<span class="hljs-params">state: TreeState, config: RunnableConfig</span>) -&gt; <span class="hljs-built_in">dict</span>:<br>    <span class="hljs-string">"""Starting from the "best" node in the tree, generate N candidates for the next step."""</span><br>    root = state[<span class="hljs-string">"root"</span>]<br>    best_candidate: Node = root.best_child <span class="hljs-keyword">if</span> root.children <span class="hljs-keyword">else</span> root<br>    messages = best_candidate.get_trajectory()<br>    <span class="hljs-comment"># Generate N candidates from the single child candidate</span><br>    new_candidates = expansion_chain.invoke(<br>        {<span class="hljs-string">"input"</span>: state[<span class="hljs-string">"input"</span>], <span class="hljs-string">"messages"</span>: messages}, config<br>    )<br>    parsed = parser.batch(new_candidates)<br>    flattened = [<br>        (i, tool_call)<br>        <span class="hljs-keyword">for</span> i, tool_calls <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(parsed)<br>        <span class="hljs-keyword">for</span> tool_call <span class="hljs-keyword">in</span> tool_calls<br>    ]<br>    tool_responses = tool_executor.batch(<br>        [<br>            ToolInvocation(tool=tool_call[<span class="hljs-string">"type"</span>], tool_input=tool_call[<span class="hljs-string">"args"</span>])<br>            <span class="hljs-keyword">for</span> _, tool_call <span class="hljs-keyword">in</span> flattened<br>        ]<br>    )<br>    collected_responses = defaultdict(<span class="hljs-built_in">list</span>)<br>    <span class="hljs-keyword">for</span> (i, tool_call), resp <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(flattened, tool_responses):<br>        collected_responses[i].append(<br>            ToolMessage(content=json.dumps(resp), tool_call_id=tool_call[<span class="hljs-string">"id"</span>])<br>        )<br>    output_messages = []<br>    <span class="hljs-keyword">for</span> i, candidate <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(new_candidates):<br>        output_messages.append([candidate] + collected_responses[i])<br><br>    <span class="hljs-comment"># Reflect on each candidate</span><br>    <span class="hljs-comment"># For tasks with external validation, you'd add that here.</span><br>    reflections = reflection_chain.batch(<br>        [{<span class="hljs-string">"input"</span>: state[<span class="hljs-string">"input"</span>], <span class="hljs-string">"candidate"</span>: msges} <span class="hljs-keyword">for</span> msges <span class="hljs-keyword">in</span> output_messages],<br>        config,<br>    )<br>    <span class="hljs-comment"># Grow tree</span><br>    child_nodes = [<br>        Node(cand, parent=best_candidate, reflection=reflection)<br>        <span class="hljs-keyword">for</span> cand, reflection <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(output_messages, reflections)<br>    ]<br>    best_candidate.children.extend(child_nodes)<br>    <span class="hljs-comment"># We have already extended the tree directly, so we just return the state</span><br>    <span class="hljs-keyword">return</span> state<br></code></pre></td></tr></table></figure><p><strong>创建Graph</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langgraph.graph <span class="hljs-keyword">import</span> END, StateGraph<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">should_loop</span>(<span class="hljs-params">state: TreeState</span>):<br>    <span class="hljs-string">"""Determine whether to continue the tree search."""</span><br>    root = state[<span class="hljs-string">"root"</span>]<br>    <span class="hljs-keyword">if</span> root.is_solved:<br>        <span class="hljs-keyword">return</span> END<br>    <span class="hljs-keyword">if</span> root.height &gt; <span class="hljs-number">5</span>:<br>        <span class="hljs-keyword">return</span> END<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">"expand"</span><br><br><br>builder = StateGraph(TreeState)<br>builder.add_node(<span class="hljs-string">"start"</span>, generate_initial_response)<br>builder.add_node(<span class="hljs-string">"expand"</span>, expand)<br>builder.set_entry_point(<span class="hljs-string">"start"</span>)<br><br><br>builder.add_conditional_edges(<br>    <span class="hljs-string">"start"</span>,<br>    <span class="hljs-comment"># Either expand/rollout or finish</span><br>    should_loop,<br>)<br>builder.add_conditional_edges(<br>    <span class="hljs-string">"expand"</span>,<br>    <span class="hljs-comment"># Either continue to rollout or finish</span><br>    should_loop,<br>)<br><br>graph = builder.<span class="hljs-built_in">compile</span>()<br></code></pre></td></tr></table></figure><p><strong>执行</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">question = <span class="hljs-string">"Generate a table with the average size and weight, as well as the oldest recorded instance for each of the top 5 most common birds."</span><br><span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> graph.stream({<span class="hljs-string">"input"</span>: question}):<br>    step_name, step_state = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(step.items()))<br>    <span class="hljs-built_in">print</span>(step_name)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"rolled out: "</span>, step_state[<span class="hljs-string">"root"</span>].height)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"---"</span>)<br></code></pre></td></tr></table></figure><p>输出</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">start<br>rolled out:  1<br>---<br>expand<br>rolled out:  2<br>---<br></code></pre></td></tr></table></figure><p><strong>结果</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">solution_node=step[<span class="hljs-string">'expand'</span>][<span class="hljs-string">"root"</span>].get_best_solution()<br>best_trajectory = solution_node.get_trajectory(include_reflections=<span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(best_trajectory[-<span class="hljs-number">1</span>].content)<br></code></pre></td></tr></table></figure><p>输出</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs markdown">Here's a summary table including the average size and weight, as well as the oldest recorded age for each of the top 5 most common birds based on the gathered data. Note that exact average sizes and weights for some birds were not directly found, so typical ranges are provided based on available information.<br><br>| Bird Species         | Average Size (Length) | Average Weight  | Oldest Recorded Age |<br>|----------------------|-----------------------|-----------------|---------------------|<br>| Northern Cardinal    | 8.3 - 9.1 inches      | 42 - 48 grams   | 15 years (approx.)  |<br>| American Robin       | 9 - 11 inches         | 77 - 85 grams   | 13 years (approx.)  |<br>| Mourning Dove        | 9 - 13 inches         | 96 - 170 grams  | 31 years            |<br>| American Crow        | 16 - 21 inches        | 316 - 620 grams | 29 years (approx.)  |<br>| European Starling    | 7.5 - 9 inches        | 60 - 96 grams   | 23 years (approx.)  |<br><br><span class="hljs-section">### Notes:</span><br><span class="hljs-bullet">1.</span> <span class="hljs-strong">**Northern Cardinal**</span>: Known for its bright red coloring in males, this bird is common across the eastern and central United States.<br><span class="hljs-bullet">2.</span> <span class="hljs-strong">**American Robin**</span>: Recognizable by its red chest, this bird is widespread across North America.<br><span class="hljs-bullet">3.</span> <span class="hljs-strong">**Mourning Dove**</span>: Known for its mournful cooing, these birds are found throughout North America.<br><span class="hljs-bullet">4.</span> <span class="hljs-strong">**American Crow**</span>: A large, intelligent bird found across most of the United States.<br><span class="hljs-bullet">5.</span> <span class="hljs-strong">**European Starling**</span>: Introduced in the U.S. in the 19th century, it has now spread widely.<br><br>The oldest recorded ages provided above are based on available data, but actual longevity may vary widely in wild populations.<br></code></pre></td></tr></table></figure><p>LangSmith流程展示：</p><p><img src="/images/LangSmith_LATS1.png" srcset="/img/loading.gif" lazyload></p>
        </div>
      </div>
    </div>
<p>LATS统一了其他Agent架构的推理、规划和反思组件，如Reflexion、Tree of
Thoughts和plan-and-execute
Agent。LATS还利用反思和基于环境的反馈的反向传播来改进搜索过程。尽管它可能对奖励分数敏感，这个通用算法可以灵活地应用于各种任务。</p>
<figure>
<img src="/images/LATS_Comparison.png" srcset="/img/loading.gif" lazyload alt="LATS与其他架构对比">
<figcaption aria-hidden="true">LATS与其他架构对比</figcaption>
</figure>
<h2 id="结论">4. 结论</h2>
<p>上述所有技术都利用了额外的LLM推理，以增加生成更高质量输出的可能性，或正确响应更复杂的推理任务。虽然这需要额外的时间，但当输出质量比响应时间更重要时，这样做是可行的。如果将轨迹保存起来（或作为
<a target="_blank" rel="noopener" href="https://docs.smith.langchain.com/tracing/use_cases/few-shot-datasets">fine-tuning
data</a>），就可以更新模型以避免重复的错误。</p>
<h2 id="官方资源">官方资源</h2>
<p>代码示例更详细说明：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langgraph/blob/main/examples/reflection/reflection.ipynb">Simple
Reflection</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langgraph/blob/main/examples/reflexion/reflexion.ipynb">Reflexion</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langgraph/blob/main/examples/lats/lats.ipynb">Language
Agents Tree Search</a></li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=v5ymBTXNqtk&amp;list=PLfaIDFEXuae16n2TWUkKq5PgJ0w6Pkwtg&amp;index=14">官方YouTube</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.langchain.dev/reflection-agents/">官方Blog</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1KJ4m1a7rZ">B站视频</a></li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/LangGraph/" class="category-chain-item">LangGraph</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/LLM/" class="print-no-link">#LLM</a>
      
        <a href="/tags/LLM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="print-no-link">#LLM学习笔记</a>
      
        <a href="/tags/Agent/" class="print-no-link">#Agent</a>
      
        <a href="/tags/LangGraph/" class="print-no-link">#LangGraph</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>LangGraph(六)——Reflection Agents</div>
      <div>https://mztchaoqun.com.cn/posts/D37_Refection_Agents/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>mztchaoqun</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年9月13日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/posts/D38_LangGraph_Code_Generation/" title="LangGraph(七)——Code Generation">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">LangGraph(七)——Code Generation</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/posts/D36_LangGraph_Plan_And_Execute/" title="LangGraph(五)——Plan-and-Execute Agents">
                        <span class="hidden-mobile">LangGraph(五)——Plan-and-Execute Agents</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <!-- <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> --> <div class="flex flex-auto justify-center [&amp;>*]:px-[16px] [&amp;>a]:no-underline  mb-[8px]"><a target="_blank" class="flex items-center text-[#A1A1A1] hover:text-white " href="https://www.beian.gov.cn/portal/registerSystemInfo?recordcode=51015602000856"><img alt="川公网安备" fetchpriority="high" width="20" height="20" decoding="async" data-nimg="1" class="mr-[6px]" src="/images/ga.png" srcset="/img/loading.gif" lazyload style="color: transparent;">&nbsp;川公网安备&nbsp;51015602000856号</a>&emsp;<a target="_blank" class="text-[#A1A1A1] hover:text-white " href="https://beian.miit.gov.cn/">蜀ICP备2024061486号-1</a></div> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
